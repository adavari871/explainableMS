{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fine-tuning we have 3 datasets: train, validation and holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "\n",
    "# keras\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import Sequence\n",
    "import keras.backend as K\n",
    "\n",
    "from config import *\n",
    "from utils import specificity, sensitivity, balanced_accuracy, IntensityRescale, sagittal_flip, translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start timing\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#percent = 0.5\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = percent\n",
    "config.gpu_options.visible_device_list = \"4\"\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zero_one_normalize = True\n",
    "dtype = np.float32\n",
    "result_dir = \"/analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/MPRAGE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p $result_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load hdf5 files and extract columns\n",
    "train_h5 = h5py.File('/analysis/share/Ritter/MS/CIS/train_dataset_MPRAGE.h5', 'r')\n",
    "holdout_h5 = h5py.File('/analysis/share/Ritter/MS/CIS/holdout_dataset_MPRAGE.h5', 'r')\n",
    "\n",
    "X_train, y_train = train_h5['X'], train_h5['y']\n",
    "X_holdout, y_holdout = holdout_h5['X'], holdout_h5['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert data to numpy arrays\n",
    "X_train = np.array(X_train, dtype=dtype)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_holdout = np.array(X_holdout, dtype=dtype)\n",
    "y_holdout = np.array(y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total datset length: 124\n",
      "Number of healthy controls: 61\n",
      "Number of MS patients: 63\n"
     ]
    }
   ],
   "source": [
    "print(\"Total datset length: {}\".format(len(y_train)))\n",
    "print(\"Number of healthy controls: {}\".format(len(np.array(y_train)[np.array(y_train)==0.])))\n",
    "print(\"Number of MS patients: {}\".format(len(np.array(y_train)[np.array(y_train)==1.])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CISDataset(Sequence):\n",
    "    def __init__(self, X, y, transform=None, batch_size=4, z_factor=None, shuffle=True, mask=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "        self.batch_size = batch_size\n",
    "        self.z_factor = z_factor\n",
    "        self.shuffle = shuffle\n",
    "        self.mask = mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.y)/self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # add BET\n",
    "        image = np.expand_dims(self.X[idx * self.batch_size:(idx + 1) * self.batch_size],5)\n",
    "        #label = np.array((batch_idx['label'] == \"MS\")* 1, dtype=np.int8) \n",
    "        label = np.array(self.y[idx * self.batch_size:(idx + 1) * self.batch_size], dtype=np.int8)\n",
    "        \n",
    "        if self.mask is not None:\n",
    "            for i in range(image.shape[0]):\n",
    "                image[i] *= self.mask\n",
    "        \n",
    "        for transformation in self.transform:\n",
    "            image = transformation(image)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.X, self.y = shuffle(self.X, self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intensity = IntensityRescale(masked=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if zero_one_normalize:\n",
    "    cis_data = CISDataset(X_train, y_train, transform=[intensity], batch_size=4)\n",
    "else:\n",
    "    cis_data = CISDataset(X_train, y_train, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabiane/anaconda2/envs/postal/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Normalized between zero and 1\")\n",
    "plt.hist(cis_data[4][0][0].flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabiane/anaconda2/envs/postal/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Scan image\")\n",
    "plt.imshow(np.squeeze(cis_data[4][0][0])[:,:,42], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_model(path, finetune=True, up_to=7):\n",
    "    model = load_model(path)\n",
    "    model.load_weights(path)\n",
    "    if finetune:\n",
    "        for layer in model.layers[:up_to]:\n",
    "            layer.trainable = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv3D)              (None, 94, 112, 94, 64)   1792      \n",
      "_________________________________________________________________\n",
      "Pool_1 (MaxPooling3D)        (None, 31, 37, 31, 64)    0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 31, 37, 31, 64)    0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv3D)              (None, 29, 35, 29, 64)    110656    \n",
      "_________________________________________________________________\n",
      "Pool_2 (MaxPooling3D)        (None, 9, 11, 9, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 9, 11, 9, 64)      0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv3D)              (None, 7, 9, 7, 64)       110656    \n",
      "_________________________________________________________________\n",
      "Conv_4 (Conv3D)              (None, 5, 7, 5, 64)       110656    \n",
      "_________________________________________________________________\n",
      "Pool_4 (MaxPooling3D)        (None, 1, 2, 1, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1, 2, 1, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 333,889\n",
      "Trainable params: 333,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# load model weights\n",
    "model_path = \"/analysis/share/Ritter/models/fabi/ADNI/pretraining_paper/model.h5\"\n",
    "model = init_model(model_path, finetune=False, up_to=None)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_weights(model):\n",
    "    # Visualize weights\n",
    "    W = model.layers[0].get_weights()[0]\n",
    "    W = np.squeeze(W)[:,:,2]\n",
    "    print(\"W shape : \", W.shape)\n",
    "\n",
    "    print(\"Weights mean {}\".format(W.mean()))\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.title('conv1 weights')\n",
    "    plt.imshow(make_mosaic(W, 2, 2), cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy.ma as ma\n",
    "def make_mosaic(imgs, nrows, ncols, border=1):\n",
    "    \"\"\"\n",
    "    Given a set of images with all the same shape, makes a\n",
    "    mosaic with nrows and ncols\n",
    "    \"\"\"\n",
    "    nimgs = imgs.shape[0]\n",
    "    imshape = imgs.shape[1:]\n",
    "    \n",
    "    mosaic = ma.masked_all((nrows * imshape[0] + (nrows - 1) * border,\n",
    "                            ncols * imshape[1] + (ncols - 1) * border),\n",
    "                            dtype=np.float32)\n",
    "    \n",
    "    paddedh = imshape[0] + border\n",
    "    paddedw = imshape[1] + border\n",
    "    for i in range(nimgs):\n",
    "        row = int(np.floor(i / ncols))\n",
    "        col = i % ncols\n",
    "        \n",
    "        mosaic[row * paddedh:row * paddedh + imshape[0],\n",
    "               col * paddedw:col * paddedw + imshape[1]] = imgs[i]\n",
    "    return mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_weights(model):\n",
    "    session = K.get_session()\n",
    "    for layer in model.layers: \n",
    "        if hasattr(layer, 'kernel_initializer'):\n",
    "            layer.kernel.initializer.run(session=session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained model layer 1 weights:\n",
      "W shape :  (3, 3, 64)\n",
      "Weights mean -0.003789090784266591\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random model layer 1 weights:\n",
      "W shape :  (3, 3, 64)\n",
      "Weights mean 0.0008080286206677556\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize weights\n",
    "print(\"Pre-trained model layer 1 weights:\")\n",
    "visualize_weights(model)\n",
    "model_untrained = load_model(model_path)\n",
    "reset_weights(model_untrained)\n",
    "print(\"Random model layer 1 weights:\")\n",
    "visualize_weights(model_untrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 96, 114, 96)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split training set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabiane/anaconda2/envs/postal/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 9s 307ms/step - loss: 1.0286 - acc: 0.4673 - val_loss: 0.8644 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69231, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/MPRAGE/weights-augm-trial0-improvement-BEST.hdf5\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 4s 155ms/step - loss: 0.9160 - acc: 0.5209 - val_loss: 0.9101 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.69231\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 4s 159ms/step - loss: 0.9610 - acc: 0.4941 - val_loss: 0.9218 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.69231\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 5s 167ms/step - loss: 0.9220 - acc: 0.4673 - val_loss: 0.8504 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.69231\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 4s 158ms/step - loss: 0.8876 - acc: 0.5298 - val_loss: 0.7818 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.69231\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 5s 181ms/step - loss: 0.8711 - acc: 0.5177 - val_loss: 0.8501 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.69231\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 5s 165ms/step - loss: 0.9180 - acc: 0.4762 - val_loss: 0.8245 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.69231\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 5s 173ms/step - loss: 0.8630 - acc: 0.4702 - val_loss: 0.8328 - val_acc: 0.1538\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.69231\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 5s 170ms/step - loss: 0.9242 - acc: 0.4762 - val_loss: 0.9816 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.69231\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 5s 173ms/step - loss: 0.8324 - acc: 0.5595 - val_loss: 0.7496 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.69231\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 1.0115 - acc: 0.4941 - val_loss: 0.7847 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.69231\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 5s 168ms/step - loss: 0.8418 - acc: 0.5506 - val_loss: 0.8974 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.69231\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 5s 179ms/step - loss: 0.8364 - acc: 0.5388 - val_loss: 0.8535 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.69231\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 5s 164ms/step - loss: 0.7884 - acc: 0.5416 - val_loss: 0.8670 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.69231\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 5s 162ms/step - loss: 0.8425 - acc: 0.5059 - val_loss: 0.8849 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.69231\n",
      "Epoch 00015: early stopping\n",
      "Trial 1\n",
      "Epoch 1/200\n",
      "28/28 [==============================] - 6s 229ms/step - loss: 1.0019 - acc: 0.4644 - val_loss: 1.1719 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.30769, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/MPRAGE/weights-augm-trial1-improvement-BEST.hdf5\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 4s 156ms/step - loss: 1.0181 - acc: 0.4494 - val_loss: 0.7723 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.30769 to 0.69231, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/MPRAGE/weights-augm-trial1-improvement-BEST.hdf5\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 5s 167ms/step - loss: 1.0878 - acc: 0.4734 - val_loss: 0.9215 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.69231\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 5s 165ms/step - loss: 1.0000 - acc: 0.5388 - val_loss: 0.9011 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.69231\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 5s 168ms/step - loss: 0.8702 - acc: 0.5327 - val_loss: 0.8174 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.69231\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 5s 167ms/step - loss: 0.9310 - acc: 0.3691 - val_loss: 0.8850 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.69231\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 5s 163ms/step - loss: 0.8629 - acc: 0.4852 - val_loss: 0.8482 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.69231\n",
      "Epoch 00007: early stopping\n",
      "Trial 2\n",
      "Epoch 1/200\n",
      "28/28 [==============================] - 6s 220ms/step - loss: 1.0220 - acc: 0.4255 - val_loss: 1.0860 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.30769, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/MPRAGE/weights-augm-trial2-improvement-BEST.hdf5\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 4s 156ms/step - loss: 0.9330 - acc: 0.5713 - val_loss: 0.8436 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.30769 to 0.69231, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/MPRAGE/weights-augm-trial2-improvement-BEST.hdf5\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 4s 160ms/step - loss: 0.9966 - acc: 0.5445 - val_loss: 0.8877 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.69231\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 5s 162ms/step - loss: 1.0809 - acc: 0.4287 - val_loss: 0.8726 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.69231\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.9054 - acc: 0.5774 - val_loss: 0.9455 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.69231\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 5s 168ms/step - loss: 0.8470 - acc: 0.5298 - val_loss: 0.8212 - val_acc: 0.1538\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.69231\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 5s 178ms/step - loss: 0.8946 - acc: 0.4941 - val_loss: 0.8090 - val_acc: 0.1538\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.69231\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 5s 168ms/step - loss: 0.8683 - acc: 0.4880 - val_loss: 0.8614 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.69231\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 5s 175ms/step - loss: 0.8087 - acc: 0.5269 - val_loss: 0.7461 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.69231\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.8193 - acc: 0.5327 - val_loss: 0.7670 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.69231\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 5s 163ms/step - loss: 0.8196 - acc: 0.4702 - val_loss: 0.7936 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.69231\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 5s 178ms/step - loss: 0.8297 - acc: 0.4584 - val_loss: 0.7837 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.69231\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 5s 161ms/step - loss: 0.8146 - acc: 0.4791 - val_loss: 0.8584 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.69231\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 5s 180ms/step - loss: 0.8205 - acc: 0.4523 - val_loss: 0.8137 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.69231\n",
      "Epoch 00014: early stopping\n",
      "Trial 3\n",
      "Epoch 1/200\n",
      "28/28 [==============================] - 7s 234ms/step - loss: 1.0259 - acc: 0.4673 - val_loss: 0.9168 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.30769, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/MPRAGE/weights-augm-trial3-improvement-BEST.hdf5\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 4s 156ms/step - loss: 0.9587 - acc: 0.4970 - val_loss: 0.8976 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.30769\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 5s 170ms/step - loss: 0.9054 - acc: 0.5209 - val_loss: 0.8528 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.30769\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 5s 165ms/step - loss: 0.8680 - acc: 0.5534 - val_loss: 0.8316 - val_acc: 0.3077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_acc did not improve from 0.30769\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 5s 178ms/step - loss: 0.9221 - acc: 0.4584 - val_loss: 0.8212 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.30769\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 5s 173ms/step - loss: 0.8901 - acc: 0.4820 - val_loss: 0.8139 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.30769\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 5s 179ms/step - loss: 0.8355 - acc: 0.4880 - val_loss: 0.8452 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.30769\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 5s 170ms/step - loss: 0.8564 - acc: 0.4316 - val_loss: 0.8142 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.30769\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 5s 165ms/step - loss: 0.8396 - acc: 0.4762 - val_loss: 0.7928 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.30769\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 5s 168ms/step - loss: 0.7993 - acc: 0.4852 - val_loss: 0.7455 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.30769 to 0.69231, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/MPRAGE/weights-augm-trial3-improvement-BEST.hdf5\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 4s 158ms/step - loss: 0.8489 - acc: 0.4405 - val_loss: 0.7955 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.69231\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 5s 170ms/step - loss: 0.7541 - acc: 0.5327 - val_loss: 0.7977 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.69231\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 5s 163ms/step - loss: 0.7733 - acc: 0.5148 - val_loss: 0.7903 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.69231\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 5s 167ms/step - loss: 0.7604 - acc: 0.4909 - val_loss: 0.7702 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.69231\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 5s 162ms/step - loss: 0.7887 - acc: 0.4584 - val_loss: 0.7673 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.69231\n",
      "Epoch 00015: early stopping\n",
      "Trial 4\n",
      "Epoch 1/200\n",
      "28/28 [==============================] - 6s 232ms/step - loss: 1.0925 - acc: 0.5180 - val_loss: 1.3498 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.30769, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/MPRAGE/weights-augm-trial4-improvement-BEST.hdf5\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 4s 156ms/step - loss: 0.9385 - acc: 0.6695 - val_loss: 0.8233 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.30769 to 0.69231, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/MPRAGE/weights-augm-trial4-improvement-BEST.hdf5\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 4s 160ms/step - loss: 0.9437 - acc: 0.5180 - val_loss: 0.8782 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.69231\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 5s 165ms/step - loss: 0.9656 - acc: 0.4405 - val_loss: 0.8226 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.69231\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 5s 165ms/step - loss: 0.8860 - acc: 0.5834 - val_loss: 0.8230 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.69231\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 5s 168ms/step - loss: 0.8293 - acc: 0.5716 - val_loss: 0.9651 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.69231\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 5s 167ms/step - loss: 0.8353 - acc: 0.5002 - val_loss: 0.8606 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.69231\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 5s 164ms/step - loss: 0.8288 - acc: 0.5416 - val_loss: 0.8056 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.69231\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 5s 168ms/step - loss: 0.7821 - acc: 0.5952 - val_loss: 0.8273 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.69231\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 5s 168ms/step - loss: 0.7942 - acc: 0.5002 - val_loss: 0.7989 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.69231\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 5s 166ms/step - loss: 0.7964 - acc: 0.5774 - val_loss: 0.8015 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.69231\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 5s 167ms/step - loss: 0.8007 - acc: 0.5298 - val_loss: 0.7732 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.69231\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 5s 162ms/step - loss: 0.8178 - acc: 0.5238 - val_loss: 0.7745 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.69231\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 5s 169ms/step - loss: 0.8024 - acc: 0.4734 - val_loss: 0.7822 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.69231\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 5s 166ms/step - loss: 0.7979 - acc: 0.5356 - val_loss: 0.7785 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.69231\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 5s 166ms/step - loss: 0.8064 - acc: 0.5002 - val_loss: 0.7667 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.69231\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 5s 172ms/step - loss: 0.8096 - acc: 0.4494 - val_loss: 0.7732 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.69231\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.8209 - acc: 0.4823 - val_loss: 0.7767 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.69231\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 5s 169ms/step - loss: 0.8280 - acc: 0.4137 - val_loss: 0.7299 - val_acc: 0.4615\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.69231\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.7914 - acc: 0.5002 - val_loss: 0.8360 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.69231\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 5s 167ms/step - loss: 0.7898 - acc: 0.5359 - val_loss: 0.7578 - val_acc: 0.5385\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.69231\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 5s 162ms/step - loss: 0.8171 - acc: 0.5148 - val_loss: 0.9132 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.69231\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 5s 168ms/step - loss: 0.8444 - acc: 0.4376 - val_loss: 0.7975 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.69231\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 5s 167ms/step - loss: 0.7998 - acc: 0.5445 - val_loss: 0.7322 - val_acc: 0.5385\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.69231\n",
      "Epoch 00024: early stopping\n",
      "Trial 5\n",
      "Epoch 1/200\n",
      "28/28 [==============================] - 7s 240ms/step - loss: 0.9724 - acc: 0.5506 - val_loss: 0.8480 - val_acc: 0.6154\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.61538, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/MPRAGE/weights-augm-trial5-improvement-BEST.hdf5\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 5s 162ms/step - loss: 0.9039 - acc: 0.5269 - val_loss: 0.7914 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.61538 to 0.69231, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/MPRAGE/weights-augm-trial5-improvement-BEST.hdf5\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 5s 163ms/step - loss: 0.9102 - acc: 0.4880 - val_loss: 0.8429 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.69231\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.9059 - acc: 0.5506 - val_loss: 0.8182 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.69231\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 5s 163ms/step - loss: 0.8906 - acc: 0.4791 - val_loss: 0.7797 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.69231\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 5s 164ms/step - loss: 0.8368 - acc: 0.5327 - val_loss: 0.8811 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.69231\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 5s 172ms/step - loss: 0.8321 - acc: 0.4880 - val_loss: 0.7780 - val_acc: 0.4615\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.69231\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 5s 168ms/step - loss: 0.8179 - acc: 0.5209 - val_loss: 0.7806 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.69231\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 5s 168ms/step - loss: 0.7822 - acc: 0.4852 - val_loss: 0.7121 - val_acc: 0.7692\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.69231 to 0.76923, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/MPRAGE/weights-augm-trial5-improvement-BEST.hdf5\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 5s 163ms/step - loss: 0.8747 - acc: 0.4108 - val_loss: 0.7975 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.76923\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 5s 163ms/step - loss: 0.8437 - acc: 0.5655 - val_loss: 0.8577 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.76923\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 5s 172ms/step - loss: 0.8499 - acc: 0.4376 - val_loss: 0.8402 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.76923\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 5s 163ms/step - loss: 0.8304 - acc: 0.4823 - val_loss: 0.8829 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.76923\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 5s 170ms/step - loss: 0.8377 - acc: 0.4852 - val_loss: 0.7608 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.76923\n",
      "Epoch 00014: early stopping\n",
      "Trial 6\n",
      "Epoch 1/200\n",
      "28/28 [==============================] - 7s 247ms/step - loss: 0.9710 - acc: 0.5059 - val_loss: 0.8401 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69231, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/MPRAGE/weights-augm-trial6-improvement-BEST.hdf5\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 4s 157ms/step - loss: 0.9483 - acc: 0.4405 - val_loss: 0.9133 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.69231\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 5s 172ms/step - loss: 0.9654 - acc: 0.4673 - val_loss: 0.8351 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.69231\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 5s 176ms/step - loss: 0.8499 - acc: 0.6102 - val_loss: 0.7993 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.69231\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 5s 177ms/step - loss: 0.8884 - acc: 0.4555 - val_loss: 0.7968 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.69231\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 5s 164ms/step - loss: 0.8456 - acc: 0.5448 - val_loss: 0.8191 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.69231\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 5s 175ms/step - loss: 0.8827 - acc: 0.4523 - val_loss: 1.7405 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.69231\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 5s 163ms/step - loss: 0.8872 - acc: 0.5059 - val_loss: 0.8711 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.69231\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 5s 165ms/step - loss: 0.8860 - acc: 0.4880 - val_loss: 0.7967 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.69231\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 5s 165ms/step - loss: 0.8289 - acc: 0.5148 - val_loss: 0.8149 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.69231\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 5s 172ms/step - loss: 0.8390 - acc: 0.5148 - val_loss: 0.7825 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.69231\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 5s 163ms/step - loss: 0.8432 - acc: 0.4880 - val_loss: 0.8396 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.69231\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 5s 162ms/step - loss: 0.8720 - acc: 0.3959 - val_loss: 0.8148 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.69231\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 5s 161ms/step - loss: 0.8248 - acc: 0.4494 - val_loss: 0.7806 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.69231\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 5s 169ms/step - loss: 0.8010 - acc: 0.5209 - val_loss: 0.7662 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.69231\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 4s 160ms/step - loss: 0.8176 - acc: 0.4048 - val_loss: 0.7860 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.69231\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 5s 167ms/step - loss: 0.7965 - acc: 0.4941 - val_loss: 0.7705 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.69231\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 5s 170ms/step - loss: 0.7769 - acc: 0.5030 - val_loss: 0.7648 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.69231\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 5s 164ms/step - loss: 0.8053 - acc: 0.4880 - val_loss: 0.7588 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.69231\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 5s 162ms/step - loss: 0.7888 - acc: 0.5238 - val_loss: 0.7754 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.69231\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 5s 164ms/step - loss: 0.8201 - acc: 0.4048 - val_loss: 0.7760 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.69231\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 5s 165ms/step - loss: 0.7441 - acc: 0.5388 - val_loss: 0.7564 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.69231\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 5s 167ms/step - loss: 0.7908 - acc: 0.4970 - val_loss: 0.7819 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.69231\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 5s 168ms/step - loss: 0.7746 - acc: 0.5059 - val_loss: 0.7688 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.69231\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 5s 164ms/step - loss: 0.7684 - acc: 0.5030 - val_loss: 0.7395 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.69231\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 5s 167ms/step - loss: 0.7711 - acc: 0.5059 - val_loss: 0.7532 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.69231\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 5s 162ms/step - loss: 0.7631 - acc: 0.5684 - val_loss: 0.7442 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.69231\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 5s 167ms/step - loss: 0.7933 - acc: 0.4970 - val_loss: 0.7316 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.69231\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 5s 168ms/step - loss: 0.7628 - acc: 0.5298 - val_loss: 0.7693 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.69231\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 5s 164ms/step - loss: 0.7547 - acc: 0.4880 - val_loss: 0.7623 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.69231\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 5s 165ms/step - loss: 0.7473 - acc: 0.4762 - val_loss: 0.7373 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.69231\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 5s 172ms/step - loss: 0.7634 - acc: 0.4941 - val_loss: 0.8658 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.69231\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 5s 169ms/step - loss: 0.7839 - acc: 0.5088 - val_loss: 0.7521 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.69231\n",
      "Epoch 00033: early stopping\n",
      "Trial 7\n",
      "Epoch 1/200\n",
      "28/28 [==============================] - 7s 252ms/step - loss: 1.1421 - acc: 0.4345 - val_loss: 0.7781 - val_acc: 0.6923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69231, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/MPRAGE/weights-augm-trial7-improvement-BEST.hdf5\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 4s 157ms/step - loss: 0.9104 - acc: 0.5388 - val_loss: 0.8686 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.69231\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 5s 161ms/step - loss: 0.9315 - acc: 0.5238 - val_loss: 0.8543 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.69231\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.9920 - acc: 0.4048 - val_loss: 0.8342 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.69231\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 5s 167ms/step - loss: 0.8988 - acc: 0.5327 - val_loss: 0.8636 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.69231\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 5s 171ms/step - loss: 0.8608 - acc: 0.5298 - val_loss: 0.8100 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.69231\n",
      "Epoch 00006: early stopping\n",
      "Trial 8\n",
      "Epoch 1/200\n",
      "28/28 [==============================] - 7s 252ms/step - loss: 1.2727 - acc: 0.4852 - val_loss: 0.8246 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69231, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/MPRAGE/weights-augm-trial8-improvement-BEST.hdf5\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 4s 160ms/step - loss: 1.0863 - acc: 0.5388 - val_loss: 1.9985 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.69231\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 5s 170ms/step - loss: 1.0340 - acc: 0.5595 - val_loss: 0.8723 - val_acc: 0.4615\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.69231\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 5s 166ms/step - loss: 0.9768 - acc: 0.4376 - val_loss: 0.8933 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.69231\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 5s 170ms/step - loss: 0.9203 - acc: 0.5298 - val_loss: 0.9890 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.69231\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 5s 164ms/step - loss: 0.9474 - acc: 0.5148 - val_loss: 0.8742 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.69231\n",
      "Epoch 00006: early stopping\n",
      "Trial 9\n",
      "Epoch 1/200\n",
      "28/28 [==============================] - 8s 272ms/step - loss: 1.0015 - acc: 0.4494 - val_loss: 0.8214 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69231, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/MPRAGE/weights-augm-trial9-improvement-BEST.hdf5\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 4s 160ms/step - loss: 1.1144 - acc: 0.3394 - val_loss: 0.8478 - val_acc: 0.2308\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.69231\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 5s 170ms/step - loss: 0.8660 - acc: 0.5534 - val_loss: 1.1648 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.69231\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 4s 159ms/step - loss: 0.9453 - acc: 0.5238 - val_loss: 0.8791 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.69231\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 5s 165ms/step - loss: 0.9673 - acc: 0.4584 - val_loss: 0.8354 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.69231\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 5s 169ms/step - loss: 0.8785 - acc: 0.5356 - val_loss: 1.4586 - val_acc: 0.3077\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.69231\n",
      "Epoch 00006: early stopping\n",
      "Training Time: 0.0h:13.0m:0.6799447536468506s\n",
      "Validation final accuracies: \n",
      " [0.3076923076923077, 0.3076923076923077, 0.3076923076923077, 0.3076923076923077, 0.5384615384615384, 0.6923076923076923, 0.3076923076923077, 0.3076923076923077, 0.3076923076923077, 0.3076923076923077]\n",
      "Validation final accuracies mean: 0.36923076923076925\n",
      "Validation best accuracies: \n",
      " [0.6923076923076923, 0.6923076923076923, 0.6923076923076923, 0.6923076923076923, 0.6923076923076923, 0.7692307692307693, 0.6923076923076923, 0.6923076923076923, 0.6923076923076923, 0.6923076923076923]\n",
      "Validation best accuracies mean: 0.7\n",
      "Validation balanced accuracies: \n",
      " [0.5, 0.5, 0.5, 0.5, 0.5277777777777778, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Validation balanced accuracies mean: 0.5027777777777778\n",
      "Validation final sensitivities: \n",
      " [1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Validation final sensitivities' mean: 0.85\n",
      "Validation final specificities: \n",
      " [0.0, 0.0, 0.0, 0.0, 0.5555555555555556, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation final specificities' mean: 0.15555555555555556\n"
     ]
    }
   ],
   "source": [
    "# training args\n",
    "lr = 0.001\n",
    "lr_decay = 0.003\n",
    "transforms = [intensity, sagittal_flip, translate]\n",
    "\n",
    "num_trials = 10\n",
    "store_models = True\n",
    "\n",
    "accuracies = []\n",
    "balanced_accuracies = []\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "max_acc = []\n",
    "\n",
    "for i in range(num_trials):\n",
    "    print(\"Trial %i\" %i)\n",
    "    \n",
    "    # init model\n",
    "    model = init_model(model_path, finetune=False, up_to=None)    \n",
    "    opti = Adam(lr=lr, decay=lr_decay)\n",
    "    model.compile(optimizer=opti, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # callbacks\n",
    "    earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "    if store_models:\n",
    "        result_path = os.path.join(result_dir, \"weights-augm-trial%i-improvement-BEST.hdf5\" %i)\n",
    "        model_checkpoint = ModelCheckpoint(result_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max', save_weights_only=True)\n",
    "        callbacks = [earlystop, model_checkpoint]\n",
    "    else:\n",
    "        callbacks = [earlystop]\n",
    "        \n",
    "    train_loader = CISDataset(X_train, y_train, transform=transforms, batch_size=b, shuffle=True)\n",
    "    val_loader = CISDataset(X_val, y_val, transform=[intensity], batch_size=1, shuffle=False)\n",
    "    \n",
    "    # Start training\n",
    "    history = model.fit_generator(train_loader,\n",
    "                        epochs=num_epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=val_loader,\n",
    "                        callbacks=callbacks)\n",
    "    \n",
    "    # Evaluation\n",
    "    y_pred = model.predict_generator(val_loader)\n",
    "    #y_true = [item for sublist in [val_loader[batch_idx][1] for batch_idx in range(len(val_loader))] for item in sublist]\n",
    "    bal_acc = balanced_accuracy(y_val, y_pred>0.5)\n",
    "    sens = sensitivity(y_val, y_pred>0.5)\n",
    "    spec = specificity(y_val, y_pred>0.5)\n",
    "    # Store results\n",
    "    accuracies.append(history.history[\"val_acc\"][-1])\n",
    "    balanced_accuracies.append(bal_acc)\n",
    "    max_acc.append(np.max(history.history[\"val_acc\"]))\n",
    "    sensitivities.append(sens)\n",
    "    specificities.append(spec)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(\"Training Time: {}h:{}m:{}s\".format(\n",
    "            training_time//3600, (training_time//60)%60, training_time%60))\n",
    "\n",
    "print(\"Validation final accuracies: \\n {}\".format(accuracies))\n",
    "print(\"Validation final accuracies mean: {}\".format(np.mean(accuracies)))\n",
    "print(\"Validation best accuracies: \\n {}\".format(max_acc))\n",
    "print(\"Validation best accuracies mean: {}\".format(np.mean(max_acc)))\n",
    "print(\"Validation balanced accuracies: \\n {}\".format(balanced_accuracies))\n",
    "print(\"Validation balanced accuracies mean: {}\".format(np.mean(balanced_accuracies)))\n",
    "print(\"Validation final sensitivities: \\n {}\".format(sensitivities))\n",
    "print(\"Validation final sensitivities' mean: {}\".format(np.mean(sensitivities)))\n",
    "print(\"Validation final specificities: \\n {}\".format(specificities))\n",
    "print(\"Validation final specificities' mean: {}\".format(np.mean(specificities)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = [\"weights-augm-trial%i-improvement-BEST.hdf5\"%i for i in range(num_trials)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load holdout set\n",
    "test_loader = CISDataset(X_holdout, y_holdout, transform=[intensity], batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabiane/anaconda2/envs/postal/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy 34.78 %\n",
      "Balanced accuracy 35.38 %\n",
      "Sensitivity 30.77 %\n",
      "Specificity 40.00 %\n",
      "Fold 1\n",
      "Model accuracy 43.48 %\n",
      "Balanced accuracy 50.00 %\n",
      "Sensitivity 0.00 %\n",
      "Specificity 100.00 %\n",
      "Fold 2\n",
      "Model accuracy 43.48 %\n",
      "Balanced accuracy 50.00 %\n",
      "Sensitivity 0.00 %\n",
      "Specificity 100.00 %\n",
      "Fold 3\n",
      "Model accuracy 43.48 %\n",
      "Balanced accuracy 50.00 %\n",
      "Sensitivity 0.00 %\n",
      "Specificity 100.00 %\n",
      "Fold 4\n",
      "Model accuracy 43.48 %\n",
      "Balanced accuracy 50.00 %\n",
      "Sensitivity 0.00 %\n",
      "Specificity 100.00 %\n",
      "Fold 5\n",
      "Model accuracy 60.87 %\n",
      "Balanced accuracy 65.38 %\n",
      "Sensitivity 30.77 %\n",
      "Specificity 100.00 %\n",
      "Fold 6\n",
      "Model accuracy 43.48 %\n",
      "Balanced accuracy 50.00 %\n",
      "Sensitivity 0.00 %\n",
      "Specificity 100.00 %\n",
      "Fold 7\n",
      "Model accuracy 43.48 %\n",
      "Balanced accuracy 50.00 %\n",
      "Sensitivity 0.00 %\n",
      "Specificity 100.00 %\n",
      "Fold 8\n",
      "Model accuracy 43.48 %\n",
      "Balanced accuracy 50.00 %\n",
      "Sensitivity 0.00 %\n",
      "Specificity 100.00 %\n",
      "Fold 9\n",
      "Model accuracy 43.48 %\n",
      "Balanced accuracy 50.00 %\n",
      "Sensitivity 0.00 %\n",
      "Specificity 100.00 %\n",
      "######## Final results ########\n",
      "Accuracy mean 44.35 %\n",
      "Balanced accuracy mean 50.08 %\n",
      "Sensitivity mean 6.15 %\n",
      "Specificity mean 94.00 %\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "balanced_accuracies = []\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "for fold, weight in enumerate(weights):\n",
    "    print(\"Fold {}\".format(fold))\n",
    "    model = load_model(model_path)\n",
    "    model_dir = os.path.join(result_dir, weight)\n",
    "    model.load_weights(model_dir)\n",
    "    \n",
    "    opti = Adam(lr=lr, decay=lr_decay)\n",
    "    model.compile(optimizer=opti,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    # Evaluate\n",
    "    res = model.evaluate_generator(test_loader)\n",
    "    y_pred = model.predict_generator(test_loader)\n",
    "    bal_acc = balanced_accuracy(y_holdout, y_pred>0.5)\n",
    "    sens = sensitivity(y_holdout, y_pred>0.5)\n",
    "    spec = specificity(y_holdout, y_pred>0.5)\n",
    "    # Store results\n",
    "    accuracies.append(res[1])\n",
    "    balanced_accuracies.append(bal_acc)\n",
    "    sensitivities.append(sens)\n",
    "    specificities.append(spec)\n",
    "    # Print results\n",
    "    print(\"Model accuracy {:.2f} %\".format(res[1]*100))\n",
    "    print(\"Balanced accuracy {:.2f} %\".format(bal_acc*100))\n",
    "    print(\"Sensitivity {:.2f} %\".format(sens*100))\n",
    "    print(\"Specificity {:.2f} %\".format(spec*100))\n",
    "    \n",
    "    \n",
    "print(\"######## Final results ########\")\n",
    "print(\"Accuracy mean {:.2f} %\".format(np.mean(accuracies)*100))\n",
    "print(\"Balanced accuracy mean {:.2f} %\".format(np.mean(balanced_accuracies)*100))\n",
    "print(\"Sensitivity mean {:.2f} %\".format(np.mean(sensitivities)*100))\n",
    "print(\"Specificity mean {:.2f} %\".format(np.mean(specificities)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 0.0h:13.0m:0.6913394927978516s\n",
      "Total time elapsed: 0.0h:15.0m:4.118826389312744s\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Time: {}h:{}m:{}s\".format(\n",
    "            training_time//3600, (training_time//60)%60, training_time%60))\n",
    "print(\"Total time elapsed: {}h:{}m:{}s\".format(\n",
    "            total_time//3600, (total_time//60)%60, total_time%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (postal)",
   "language": "python",
   "name": "postal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
