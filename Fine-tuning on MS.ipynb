{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fine-tuning we have 3 datasets: train, validation and holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "\n",
    "# keras\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import Sequence\n",
    "import keras.backend as K\n",
    "\n",
    "from config import *\n",
    "from utils import specificity, sensitivity, balanced_accuracy, IntensityRescale, sagittal_flip, translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start timing\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#percent = 0.5\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = percent\n",
    "config.gpu_options.visible_device_list = \"5\"\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zero_one_normalize = True\n",
    "dtype = np.float32\n",
    "result_dir = \"/analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p $result_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load hdf5 files and extract columns\n",
    "train_h5 = h5py.File('/analysis/share/Ritter/MS/CIS/train_dataset.h5', 'r')\n",
    "holdout_h5 = h5py.File('/analysis/share/Ritter/MS/CIS/holdout_dataset.h5', 'r')\n",
    "\n",
    "X_train, y_train = train_h5['X'], train_h5['y']\n",
    "X_holdout, y_holdout = holdout_h5['X'], holdout_h5['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert data to numpy arrays\n",
    "X_train = np.array(X_train, dtype=dtype)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_holdout = np.array(X_holdout, dtype=dtype)\n",
    "y_holdout = np.array(y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total datset length: 124\n",
      "Number of healthy controls: 61\n",
      "Number of MS patients: 63\n"
     ]
    }
   ],
   "source": [
    "print(\"Total datset length: {}\".format(len(y_train)))\n",
    "print(\"Number of healthy controls: {}\".format(len(np.array(y_train)[np.array(y_train)==0.])))\n",
    "print(\"Number of MS patients: {}\".format(len(np.array(y_train)[np.array(y_train)==1.])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CISDataset(Sequence):\n",
    "    def __init__(self, X, y, transform=None, batch_size=4, z_factor=None, shuffle=True, mask=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "        self.batch_size = batch_size\n",
    "        self.z_factor = z_factor\n",
    "        self.shuffle = shuffle\n",
    "        self.mask = mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.y)/self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # add BET\n",
    "        image = np.expand_dims(self.X[idx * self.batch_size:(idx + 1) * self.batch_size],5)\n",
    "        #label = np.array((batch_idx['label'] == \"MS\")* 1, dtype=np.int8) \n",
    "        label = np.array(self.y[idx * self.batch_size:(idx + 1) * self.batch_size], dtype=np.int8)\n",
    "        \n",
    "        if self.mask is not None:\n",
    "            for i in range(image.shape[0]):\n",
    "                image[i] *= self.mask\n",
    "        \n",
    "        for transformation in self.transform:\n",
    "            image = transformation(image)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.X, self.y = shuffle(self.X, self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intensity = IntensityRescale(masked=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if zero_one_normalize:\n",
    "    cis_data = CISDataset(X_train, y_train, transform=[intensity], batch_size=4)\n",
    "else:\n",
    "    cis_data = CISDataset(X_train, y_train, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabiane/anaconda2/envs/postal/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Normalized between zero and 1\")\n",
    "plt.hist(cis_data[4][0][0].flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabiane/anaconda2/envs/postal/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAScAAAEICAYAAAAdoDKiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJztnXmUL1V17z8HEIwj4MikoCCoKKAEUSASJwgiPhNQExXi8wV9RtTASwA1UbKSGBKiKBjjRHRpwiAogwOTwAqKoJdBmQeRURSMoMaYROS8P36/z6/273TdS8O9t7u6e3/Xuqu7q05V7XOq7jnfvc8eSq2VRCKRGBrWmG8BEolEog85OSUSiUEiJ6dEIjFI5OSUSCQGiZycEonEIJGTUyKRGCRyckrMGUopV5ZSdp1vORILAzk5LRGUUnYupVxQSvlpKeUnpZRvlFJ+cy5lqLU+s9Z63lw+M7FwsdZ8C5BY/SilPAr4EvB/gROAtYFdgP+eT7kSiRUhmdPSwNMAaq3H1lp/XWv9Za31zFrrd21QSvmjUsrVpZSfl1KuKqU8Z3z8kFLK98LxV4Vr/rCU8vVSyhGllLtLKd8vpfzO8oQopdxUSnnJ+Pf3lVI+X0r53Pjel5dSnlZKObSUcmcp5dZSysvCtW8M8t1YSnlzc+8/K6XcUUr5QSnl/5RSaill8/G5dcYy3lJK+VEp5Z9KKb+xqgY3sXqQk9PSwHXAr0spnyml/E4pZb14spSyD/A+YF/gUcBewL+PT3+PEct6NHAY8LlSygbh8ucB1wKPBf4O+FQppcxSrlcAnwXWAy4FzmD0TW4E/CXwsdD2TmDPsXxvBD4YJtDdgQOBlwCbAy9snnM4owl62/H5jYC/mKWMiflCrTX/LYF/wNOBTwO3AfcCpwJPGJ87A3jHLO9zGfDK8e9/CNwQzj0MqMATl3PtTcBLxr+/DzgrnHsF8B/AmuO/Hzm+17rLudfJygwcA7w/nNt8fO3mQAF+ATw1nH8+8P35fif5b8X/kjktEdRar661/mGtdWNga2BD4Mjx6U0YMaQZKKXsW0q5rJRyTynlnvG1jw1Nfhie8Z/jXx8xS7F+FH7/JfDjWuuvw9+Te40Z34VjY/49wB5Bjg2BW8O94u+PYzRpXhz6cPr4eGLAyMlpCaLWeg0jFrX1+NCtwFPbdqWUJwOfAN4GPKbWui5wBSM2MmcopawDnAQcwYjtrQt8JchxB7BxuGST8PuPGU10z6y1rjv+9+ha62wn0MQ8ISenJYBSylallINKKRuP/94E+H3gwnGTTwL/r5Ty3DLC5uOJ6eGM1KO7xte9kW5Cm0usDawzluPesdH9ZeH8CcAbSylPL6U8jGBPqrXex2iC/WAp5fEApZSNSim7zZn0iQeFnJyWBn7OyHB9USnlF4wmpSuAgwBqrZ8H/hr413Hbk4H1a61XAf8AfJORCvYs4BtzLXyt9efA2xlNQncDf8DIZub5rwIfBs4FbhjLC52rxMHj4xeWUn4GnA1sOSfCJx40ythAmEgsGpRSns5o8l2n1nrvfMuTeHBI5pRYFCilvKqUsvbYTeJw4LScmBY2cnJKLBa8mZFN6nvArxl5wycWMFZKrRs7v30IWBP4ZK31b1eVYIlEYmnjQU9OpZQ1GXkev5SRY9+3gd8fG1ETiURipbAygb87MPIOvhGglHIc8EpguZPTGmusUddYIzXJRGIp47777uO+++67X1+5lZmcNmLaE/c2RtvVUyil7A/sD7DGGmuw7rrrrsQjE4nEQsc999wzq3YrQ2P6Zr4ZOmKt9eO11u1rrdvPPh40kUgsdazM5HQb02ECGwM/WDlxEolEYoSVmZy+DWxRStmslLI28FqC124ikUisDB60zanWem8p5W2M0m2sCRxTa71ylUmWSCSWNOY0fGWttdaqaRBPJJY27rnnHu699977NUDnvn4ikRgkcnJKJBKDRE5OiURikMjJKZFIDBI5OSUSiUEiJ6dEIjFI5OSUSCQGiZycEonEIJGTUyKRGCRyckokEoNETk6JRGKQyMkpkUgMEjk5JRKJQSInp0QiMUjk5JRIJAaJnJwSicQgkZNTIpEYJHJySiQSg0ROTolEYpDIySmRSAwSK1PxN7FIsLJFLlZVsdQoRxZgTSRzSiQSg0ROTolEYpBItW6RQdWoVYv6VLc111wTgP/5n/+Zce6+++6b+hnvt8Yaa0xd3x5fkTx9qlufbMtTNVPdWzpI5pRIJAaJZE6LFDIP2c3Pf/7zyblHPvKRAOyxxx4A/MZv/Mbk3KMe9SgAnv/850+1/eUvfzlp89///d8A/Pu//zswquAKcM0110zayMZ+8pOfAHDnnXcC8F//9V+TNo94xCOm7nfbbbdNzv3qV7+akr/tV0SyqcWJZE6JRGKQKCu7jfxAsNZaa9V11113zp632NH37v7jP/4DgM033xyAzTbbDID9999/0majjTYC4I477gCm2YyM5de//jUAD33oQwF4/OMfP2lz7733Tj1T5uM1AI9+9KOn7nfTTTcB8J//+Z+TNttvvz3QMa/vfve7k3OXXnopACeeeOLUs2Ry0LEqvynliDa01nYWsTz7XGL14p577uHee++930FP5pRIJAaJZE4LCK0dSaZwwAEHTNrssssuQMd0tDVFe45MYa211ppx7olPfOLUM2U1kbH4DpXj9ttvBzq2BLDOOutM3U9W9LjHPW5Gv2Rn8XqZ1tprrw3Awx/+cACOPvroSZutt956Sn4Z3d133z1pc+211049K9reZHr2YyjOqIsdyZwSicSCRk5OiURikEi1bqBYkbFWdebP//zPAfjpT386Oaeq4ja9BnJVJ+hUJts85CEPmZzTmPzYxz4WgFtuuWXG9RtvvDHQqVE//vGPgWmXBNXAG2+8EejUOQ3kAE960pOAzs3grLPOmpzbbrvtAHjMYx4z9Xxlhk6t/epXvwp0rhGqq9A5htomPkP84Ac/ADpjfbx+Nqpa2ybVuxUj1bpEIrGgkU6YA4XM6SlPecrk2Cte8QoAnve85wEdK7rrrrsmbdZbbz2gM/LKWDRsQ8eUfvGLXwDwghe8YHJOViUDe8ITngBMG5llU56TDUcGpzOnTEd5NGxD57QpYznnnHMm5zTsb7DBBgD88Ic/nJIZOqa21157TckYHTft/8477wx0LA9g/fXXn+rH9ddfD8BVV101aaNBXkapQT26Kyi/52IYz1xqJosNyZwSicQgkTaneYS2CW0n0DkmuuIfcsghk3MyJBmT7y7aYVy1tQdp+zHUBLqQEl0AnvGMZ0zOaU9qmYJ2IejYh20Mbdlwww0nbXRlaOX52c9+Nmmj64BuBzFERuYlcxFxrLQN2faGG24Aph0uZWp+d9ElQjYmk7zwwgsBWLZs2aSNLPXss88GOtvXDjvsMGkju7vooosA+OY3vzk551g5Dr6zpZy7apXZnEopm5RSzi2lXF1KubKU8o7x8fVLKWeVUq4f/1xvVQieSCQSMAvmVErZANig1npJKeWRwMXA/wL+EPhJrfVvSymHAOvVWg9e0b2SOU1D28hf/dVfTY65CvcxnjYlicwl2ljcDfOnTCPaemQqOkbKlgA23XRToLPfyGbiTpw7cH47Mg931qBjM57TUTJ+bzIfQ21kLgBbbrkl0DEu+6p80LESmZIsL4bIbLXVVkDHNuNOnOE72pxOO+00AN7whjdM2vh8WZm2ON9T7JPvLD5fNnXccccBHWuN49CyqsXOpFYZc6q13lFrvWT8+8+Bq4GNgFcCnxk3+wyjCSuRSCRWCR7Qbl0pZVNgO+Ai4Am11jtgNIGVUh6/nGv2B/aH/mRkiUQi0YdZT06llEcAJwHvrLX+bLbUs9b6ceDjMFLrHoyQiwWtGnTMMccAnRMgdCqX6liMN/v+978PdEZZt9VjvJquBKoWqkwxpkx1yLi36GagO4DnHvawhwGdChRlVFVSVtWjeEx1zIUpPkuj+RVXXAFM54PaddddAbjyyiuBzujfl1dKtdbsCtHRUzVMOXQXgE41sz+//du/DUwb7VXrNtlkk6lzsR9uVPQ5tW677bYAnHnmmQDstttuAHzve9+btPnWt75FYiZmRWVKKQ9hNDH9S631C+PDPxrbo7RL3bm86xOJROKB4n6ZUxlRpE8BV9daPxBOnQrsB/zt+Ocpq0XCBYo+46Yr64c+9CGgW4Wj86Ks5txzzwU6Z8R4vdvrMoS43d7mVtKgHrfXZR8aveP1yq1MMUeTcFND9mAfI2ORFWkAlrnErXyf5Za+DCZeJyuUFUVWo5H/Rz/60ZQ8ERrZW9Yar3c8dMq89dZbJ21krsrtxkBkorJL7+dmQOz3Rz/6UQCuu+46oHOoBTj//PMBuOCCC4DOyTU6vrb51he70Rxmp9btBLwBuLyUctn42LsYTUonlFLeBNwC7LN6REwkEksR9zs51Vq/Dixvmn7xqhVn4cIVTduKLOJ973vfpI1ZKWUxroyRTbgyuxpvscUWk3Paplz9/antB2au3q78cRXWjuK2erw+MgKYmcMbOlaljN4vsiyvU0YZRHRpkOXpyhCdOFsHS8NqZB7QsbOW+cT72DedSKPNSnlljjKwCN+j9j2vidlDZXNmGI3sTpZ58cUXT/U/jpXhQwYue722OIBjjz12ahyWAnL7LJFIDBIZ+LuKIBuS6bznPe8Bpp0oZSWu0O6oueJDt2pus802QOf8FxEdCeN9oGMzrsyyrciA2syP0dYjC5JNtPatKO93vvMdoNv1iq4iyqQdqC9ERcicIoPzehmLz4zPaHcElSOOp0xFJ9DYV6+3b9r7ooOlzMfnKr/jHI95v+iwKmP1vZomJn4Xyqtzq898znOeM2nj7zp1/uM//uOMfvTlSV/ISOaUSCQGiZycEonEIJFq3QNAa/SO9P0d73gH0Kl1UUVpr9eJUvUqqhoasFUxovOjrgQ6/T3zmc8Eum136OLbVLnMaKkTIXTG3Ci/UK2zj62DIXTqqfdWRYmqn6qGapnqYVRJNZZ77Oabb56ce+ELXwh06pCyRpVNldH+6DgaDdLe2zGPKrBOrW5IPPnJT56SK46H8vuuYl/9XfUubnCo/qlyKWscB10plN9nRjkcc4udxnena4ptFou7QTKnRCIxSCRzegBw9TOH97vf/e7JOY3crtqyohh+opHalVVjaTSOyjRkHtEA7O877rjj1DMjm3D1/M3f/E2g36HPVduVPrIA+2ibpz/96TNklKm5srcuBdAxR5mG94usxjxS5j+KZZwM6fijP/ojAC677LKp+8XrZQgaiyNLdDxaBgTdOzLs5mlPe9oMGWVcbe6naHz2PsoRjeWywZYtR+aksV4mKiOM70U3Bd9ZLHIqq22ZU8RCZFHJnBKJxCCRmTAbtIUrI3baaScA3vjGNwLT+ayFK7urZ1yxXAltoz0p3icyHJiuemJQr7YJ28ZVvHUlcJv+8ssvn7RpnSZjPmxXdPuvbSO6AChvm4coshplciu/LbIJnWOkwbGRKcgKZRUylsgS/V2mocNmZHBtfqtow9NlQFn/7d/+bapf0OUeb58VnSEdG+1J8RtXFm2BMrfIqHXQfNaznjV1vz6nUMe6L8ja3OdHHnkkMG0n9DscAoPK6iuJRGJBIyenRCIxSKRaN4bjoKqjcdJ8SACvf/3rgY6ixzJDqgaqD6oGUUVQZZL+S+NjaSe3t9v7QKdq+SwN61EtVEWLtB+m1bI271EsGqD60roARDm8TpVPVSeqoO3We9/2uCl33d6PKofvwawEGuSjsVqovqzo2+pLdKgBWRktJhHj3j7wgVEiDjMVOHZxzDT++376Ygzthx7i8dvRM1wvcK+JrhWtITwa9h1b+6MqfPjhh0/atFEF84lU6xKJxILGcKbTeYYrq8zBYpax+IAlg/qMuy0DlU30raKufhqE+wpetiwJOlbkqukq3pZPgs5Y3uYBisfarXToGJNyuCpHVtOyofZv6MbzqU99KtC5CZiZId5TVhRlVCbP+YyYNcFnaAiXwcRCCzIc+xNdImznO/qnf/qnqftAx2odY10K4nu1HzLJmLGgbdNuhkDHalpnzmjQfvaznw10bhzR7cI+6kRqUQfLjEFXzGIhxd8lc0okEoNEMqcxXEUPPnhU3UobQSxX5Gop41C3h25F9Kerep9twEwB7aoMM/NiR9jOc/7ss2t5H+05fazGbf6+MuKytD42EO8V+xzRuiQY1hP7pR1HVhFZkexBO1JfqW+v87302QJlH45HtIu1WQl8RmzjOXNEyUijzcnrbNu3XS/j0j0gjpmsrrXT6XgJ3bfmNxPZtmFMLZOODLD9LobgUnB/SOaUSCQGiSW5W9cXGGmOZ1ddbSWxDLerjm1irmgZgU6Q9jM6OHq99gb1/758Sq3NJ7ZX/jajJnS7jF7XF7bRoo9NtPmc+sJo2l22vm/JeztWUVbv3TKYtt8wM7NmbONY91WTkalos+l7ZzJHd0pjNRuZl6xERqcNB7r34L1j4K+syjb2OX4XHjPsxr+VBzq27fuNtru2mKffU+yrWTXNMxbHeq6Ru3WJRGJBIyenRCIxSCwptc6+Smn333//yTkj0qXfGlfj1qvqjBQ/JutXfVHFUX2JW86qD6ojfeqlBmhpf7xeA6djKJ2PW87GbOkSoIoT33P7/Kiy+QyP2f+oZrV5mGwT79MWUejbHm+34GOuJY/5LMc8PsPntpkColqnauOxGM3v2Cpbez/o1Cflvv3224Eu2wPMLHIaHR79vd1MiRsMrVOsbaPRXYdd5YhFHHyu46kqGzc67PeJJ54IwOmnn858IdW6RCKxoLGkXAlcWTR4WvIauihzzxmhHldandtkLNGQ3CbAd6WOq19fYccoF8xM7G/ZIOhYzSc+8Qmg256OmTBd/ZVNeVZkdI+syswHjsPv/d7vAdMrvexBh1XZQZ+7gs+ViUZDsP3x3pElKndbECGOuWOkkVhE51ihHJGdKYv3jLIJszm0bhtxPNsiEH2hMo5xyyjjvVqXCvNVQRfqo5H8vPPOm5zzG/Gbs9T5lltuOeP5fsPzyZxmi2ROiURikFgSNqeWseg2EPPlyHC0Ubgax5VbfV93gbgKt458bX7reG9XVplPHBMzT5rjJ5YAsr0rvXLEfNKuvi0riiu1bTzWZ3NSVlnBW97ylkmbNj94X35uWZBj5jPjs5RbthfHumUqLTONfWyZS8xEKexrZK06NDpGyhr74Xhoy2udU2NfDUqOTLgt1d46jvYdk7VG5qPrgvm5oruDbOqaa64ButAf2Va8t9/n1772NQC++MUv0mJ1O2imzSmRSCxoLAnm5Er/l3/5l0B/GW+Pqf/LBvqyTMoqoj1Ju09b4LDPRuJO3g477ABMO/RdeeWVQLc7o40AupXdVdAVPpatPvfcc4GuGKeraOxru0sW0e4gyvxiALT3chX2PvFbap0OvSaymhVVJLFvMliZR8wgqTOssvZlwmzDbyJzap1qlbUvSFrZPNdnS+yzNfmuvN77RfuWbdqwIneQYeYuX3Rm1UHTY34nMQDasXb83ck77LDDZvRjdSOZUyKRWNDIySmRSAwSS0KtU1V7//vfD3T0OapcUnvVjz6qLhWXNscI+za+rM2MCTMN6RowVe+gyyPls+L1bfS7qkLc1lYlMN/PUUcdNSVz7KPxg/EZlmJSjbPEVMwIamGAVr3sK5gpHI8oh2qu30TcPLD/xiFqAI7xYqps7XhEOeyrql40dvtuba+BPBqrVfXa7Aaxf7E99BvE7Y/vqq+oRFsAI5oU/K5i5gbhOC6vHBd042b8nvIfeuihkzZ9914dSLUukUgsaCw65tTXn1e+8pVAV+ZHx8q4Ld06TbqKxxXO1afNjQOdY6bH2lzk0DEnnRc1YEbjpqu58sQQGZmCuX3a0kxRDtmNjOEjH/nIpI3G0L//+78HppnT5z//eQBe8pKXAPDqV78amDaIm2FR471y9YWWeKzP+VDjdl+IjZCd9jm1yhDss+8sGs3bwqExtEWHU7Njys5i+Skh42rlge4dty4NMLNIqv2Ped9bBucz+vIx+T32GfbbrBVxrO2b35PvzFLm0L3P1V1GKplTIpFY0Fh04St9s71VLdSp+zJQynQ81hZRhJkrUt/Wsde3+amhW1HPOussoMt0GBmD92zzQkHHAgz67AsJcYVvA13f+ta3Ttq8613vAjoGtc0220zO6YLgc7/97W8D8MIXvnDSRmdQGYsrfWQM9qPNDxXb+HzbRNtZ64Qpa41j1QbsOmYxnMd7+tzIOBwrnR1lFfEbchx8Vp8TprIa1hOvlzHapmVQ0DEkx6gNEo6/9+Xnsk9tkdToqGkfLfP+uc99DuicOvvuM99I5pRIJAaJnJwSicQgMWuDeCllTWAZcHutdc9SymbAccD6wCXAG2qtM8O6A+bSlSCqXEcffTTQpdyVtsatWum/qkHr4QwzU8fGZ0jXHc82BW1srwFV1SumAm5j+/oS4SuH6ul22203aWN8l/FWto2R+katf+ELXwDgsssum5zTlaHNjhBj/JRX9cUxi+PhONjH1qAcf19RMQhVcccjqmxtLFxf7qk2G0F0RVA9dlz9GdUyVSSPff3rXwemY9L22msvAPbYYw+gMyxD9z5atTKqda3K5jPjWHmd/Yj/bx23dhNFV5F4nbI5npdeeumkjRkY4gbN6sDqMIi/A7g6/H048MFa6xbA3cCbHpiIiUQisXzMyiBeStkYeDnw18CBZbSMvAj4g3GTzwDvAz66GmR8UIirX5u5sq9gZbvC+ndfgcQ+h0JXPQ2lfYUiXa2i8ydMMw4Nr8ZLxYKXbn27suouoDMndPFY9lGmEWU1Wl0HvLhSmsdKY3XLfKDbLGjLWEVjc+vo2ro/wMyiC9EQ22aA6DPyaphv4+ei+4XvQebYVwhVuWWJkbG07+rYY4+dkg+6rJgryq/VMvK+8lP+7GNHbVxlNMi3xVb7sjL4rXidz49yyMQdsz5n0rnEbJnTkcCfAf5vfgxwT61V/nwbsFHfhaWU/Uspy0opy+bSpyqRSCxs3C9zKqXsCdxZa724lLKrh3ua9s48tdaPAx+Hkc3pQcr5gBHtDtpWXvGKVwDdShlL+LjqteEKcXV3hdJeENmEq5U2Ev+ONid/j8dgmp25srlSxcKdN954I9AxMFc6V0XoVlafr/wxNEFm4IofFw3dCmQ42qOiHGZMaHN3RybaZuJUxr4cWI5HfB9t8UffZ3RF8BltVL9b+tCxTWWNjrdtVkt/Rruo7/yzn/0sMJPJQTdmumFEltFmwLSPUQ7ZnM/VtUB7FXS5x/rypLfFOL0+5jm3NJbXy44iSxwaeZiNWrcTsFcpZQ/gocCjGDGpdUspa43Z08bAD1afmIlEYqnhfienWuuhwKEAY+b0/2qtryulfB7Ym9GO3X7AKatRzpXCBRdcAHSr1+te9zpgeoV19TH04bjjjgOm84wLV/UnP/nJk2PaGVx9ZAhRp2+d5Fxh+9iZ5bsjq2ozN7rqRVakTaa1YxjwGa+XAcYqHbbXOa8vX7o2Hdu25dFh5u5lX1Bp63Aay4hr13Kl78tk2TpxWpY7BinbXtkiG2nzWTl2sZilDPrMM88Eut2+nXbaadLGsemruOMzHLO2WGls4+5hayeD7ltzp9VvAbpxtG/eL+4IWvrdcdW+FsNoZLdtGMt8YWX8nA5mZBy/gZEN6lOrRqREIpF4gOErtdbzgPPGv98I7LCi9olEIvFgsehi60SkpK0RUPUuZgxo8zG95jWvAaaNiqp8rUsCdDRd2t9uC8PMeLe+Io6qX6o4cevcWLqrrx65m2nEj9vzpvVti2LGfuicp+oWo/Dtx5Oe9KQpmaMh2ntqgFWtimqSY9wacGNf20j7vu1x1SrVjyiHv5tzascddwTg5ptvnrTxnfc5gbb5n5Q1uiIccMABwMwyWGZtgC5Ncut2EJ/XxgZG1U+TgCq049oXB6jqFVVgx1rjv/2IRvu2/JbyfOYzn5m08ZuZb3VOZPhKIpEYJBYtc4pwtXL16Ctl1JaEdoWKDm1tae24wriyutpprI3Mx+dpODUrQV/5bIt8xlAIw0ZkN7KCuIpqFHU1bfP4xL65isbny7ze/va3A/DSl74UmGZny5YtAzp21bc97rhpiJV1xvu0zn5RRu9pJky3xyM70UH1qquuAuCggw6aui90BSef+9znAtPZFby3oShunESjeQx3AXj5y18OdG4DsW++8yijbFBjvawubtu3W/+y576tfe8Xw5p8XvvOIyP2G2mN5nFTyOtXdz6n2SKZUyKRGCSWBHOSDbkdq40ksiKd3AztcBWJq4+rjqtWXKFd6duS1jGoV/tJu3pFNnHqqacC3UoX72dgqUVBZVCxZPryillGB0ftILbVdgVdZkQdAr/85S8DsPvuu0/amI+qZZDR8fV3f/d3gW7L3XCcuL1t//tcEWQhtpHBRMZgKMmb3vSm5d7HQF3zUsUA5ra9YxZDU5R36623Bjq2Zn9g5juPjKMtNS47jCxRpuT3JLOOrLsNJI9uBpttthkwHTYTnw3dd9zmW4/uMOadHwqSOSUSiUFi0TGntigkdPaGl73sZUBnX9KuA91K7Qrr7lB0gtxll12AjlXE1c/VTh1eVhKZl+xFu8PZZ58NwN577z1p4yrsTlosuKltwRVVx8ZoFzHERRuHdpTIjpRVu0l00DQ0xWBi+//pT3960sbxdMXWYdRS6gCnnDLyyb3wwguBzj4V7TkyljajJXR2HMdM5vDhD3940kaWK8t01y6WmdeuZJv4PlrnxXaHEOBFL3oR0NmqrrvuOmCaAbZOsTH3t9+RO6R9GT399nyu7znu1rVVXCIT9nltHvv4fV5yySVAZ1M0HCn+H2ifNd9I5pRIJAaJnJwSicQgsWhKQ7X9iKrOPvvsA3QljaTxccu3zaJ42mmnAZ16BJ36In2OBmDptv1rMzlCpxJ86UtfArot/Whs/tjHPjbVjxiDpZOdfdM1QdUFOnVDFVT867/+Ky1sGw2vxqW1DokahKGLcFeNsV/RNUO1TPkd62233XbSpi1s0GZrgE7VUf2I7grGl/k+VR37ip36XmJEjYnyAAAeJ0lEQVTcnNepFqneOs5xPFQh/+Ef/mHGM3zHfoPxWzzppJMAeOc73wl0KnEcqz/+4z8GYL/99gP6836de+65QOdoGtXKb37zm0D3XbrREzNJnHfeeUCX6dRvJsbozRWyNFQikVjQWDTMqUVc2Q488ECgYyqumNHg6Di4ampAdMWEjg30GXA1Mrs1qwHalQo6w6f30XgdjZIayz0XjZNtEcjW4RO6rW4Nn7KByEpOOOEEoNsgiAZcV1u3yt161pkSOjbp2LiaX3/99ZM25s5ye7uvjFZbLikaq9vsCr4fGQB0BnCdSC+66CIAzj///EmbPuOw0FjtvWW/kRH7/t785jcDHdOIDM53L0uM7+wZz3gG0G0eeH10Yzn55JOBLgOGbgIxY4AbE947frt+F/bD7zt+n8LrHLP9999/RpvVjWROiURiQWPRMSf7s+eee06OqYtbXNNt/r7tYNHXRluP29LRbuDK7GqlK0AMP3G13WGHUTIHV/WvfOUrkzZtueq+TJgyQFfM6O6g/cP7KIfPBDjmmGOm+hptXr4f7R26VsQcSdorZGfmLY/2JF0q2oDd6ErQltaOjKO9zrGKTPaII44ApplflD0+ry/vu+yhDQSPMrb5oN773vcCXcgMdMzVbygGMMsqW7cJQ5egC+TWFcP+RPcPWaXsVPsadN+qtjv/jt90m0nUvu67776TNn02s9WBZE6JRGJBIyenRCIxSCw6tU76bPxZhEZWjc5RZdNgK5W2bcy706a1jUZJ6bKqVl9OHo3Dqh3S92i8d5teA3SMd3LLXq9rDafR2Kxa9/rXvx7oVIXoUaz8f/EXfwF0RlvojLuOkQb+3XbbbdJGr2nl19M8fksafFVj+jYRlMlxiQbgtiCBYxbHSlXnjDPOALqikDG1srF9vs/4DFVPVTTdR6KxW5VZY7eG/lhUQjXQ7yOOg9+734PfhyoxzCwK2haygM6U4LuO8Xyqqr4zZY3qpf1QPVc1/+QnPzlp07cJszqQal0ikVjQWDTMydnelfWoo46anHO1dIVzuz0622l4bp0PY/S3q4+xW3EVlym0bCiyM42gZiqQbcWVqs3xFJ/vaukKZ9xdzPzoyq78Zs+MmQtkZcr61re+dXLO0toW1/ybv/kbYJqd6QphH/sS+0eGAh3ziU6pbTaD6HAqm2hLwPcVvDTnlOMRo/NlLG0BTejep4UFfC+6WkC3IdBmLJCZxuu8X2QsLaN2U8U8U9AVLfA9KmM0mvt9+Yw4vrGoKvRn9JQdt/mkohuKDqarOyNmMqdEIrGgseiYk6v6Bz7wgck5bQuuxjomxrAN7Tmu3o5LXM3dlnc1j6tXW0K6dTCEjr2Y8dBVNLIDV01Xvb4QGVfRtmQ3dLYJf3p9ZGBt4U1tNQDf+ta3gG7VNvQn5qVqV1b/7hsP2VlfaSd/l031lVRS/tZdAGY6Jjq+0R7TlmKKrKa1ETmeke0effTRAHzjG98AOrYWnRfta7ulH+X33trZYi50r7M/2rPi9+kYaw+L70OnXNm2304sZb/lllsCHev3XHSt0Ck39l+sShaVzCmRSCxoLLp8Ts7wkbG4SrlStxkHoWM6rqx9Zby19cg44urXriw+w7CFKJOrrytlXKlkCH35oPzdVdS20ebUFq/U5hTbeG/P6UQJ3e6g7MN+9O2k2Q9tedGG1wbxageJYx53o2B6Ffe5PkPGER0kPadsVkGJkO3KQqKm0FZk8e/o1CpztCy743L88cdP2rztbW8DOkYc+y7TUf6+KjS2l0nLcqMzqe+1tRdC9z5lTH6fMXRKORwPd6Vj/vihIZlTIpEYJHJySiQSg8SiU+uk5JG+S5elxP7dV2BRmqvqFNuI6KQnWgO6hvlYBEHVTxXHZ/bJ4bHo7GcuIqm5qoLGfOgofeu0GFUNZW3VAOgi/c05pSoZU9+qzqriOFYxN5BqSOsKEA3SrbtBVKdUe3yWYx7HymOOmWplVLfdKvfeUU1uC0y0xSmjHB5TLY3qqep+3/OVLcZhwrQzqnIoY2tgh+4de+/4ztosG8bdxX54XTSkw/T/k6Gk5xXJnBKJxCCxaJhTWzgzrtCuFrIJV6S+EtsaZV1xY9hHW1QzGjXb0kW2iQUvW+hWEQ3Byub10cHOPhku4uodV2GZheMgY4pGd5+hAdlt5tjebeXWxSI+o82D1JZIis9SHhllbO97iP2QzdhnV/XYD69rw4miw2iUG6Y3DGzfunRElqP8Zqs87LDDZrQx20XrJAvdN+f7bOWJ/bBvvt/Idu2TxyLL8ZzXy6oiu3OMZPL2OTpqOtbx/8V8IplTIpEYJBYNcxKu5rHMsiuLW+auKHEVlT2ov7vNHjNAtnacyBR8rixNBhVzmbsya9fSRtNXjtwQjPgM+6FsrdsDdCuhW82tE2Lbb5i2oZlbylJIsrtoc1JGV29l7SsmqYwtA4KZtre+bJmtjNHBUTamPN4nMo6WyUbGoyyt20ZkDo6n7+hd73oXMO3U6ra8rCTazvxmlMM+xr76XbTyx762GUFjH1v3Gd+V3wl077zVHmJO9RWN/3xgWNIkEonEGIsmfKVFDJo0lMVV05U+6tsyJFOMuKrH3Q3ZSBtiAt3K6irepvqAmXaDdpcoHvNnvL5NP2K4RmRn9k2mYs7t6Lz4mte8Buhyl+s8CJ3ToRk87WNfBst2dycyBllAm50x7jK1bCAGoXqudYyMbMKdTK/32+qzmfj8yFLbUCPfa3yGNkOfr30wvjPlkJ32fTOtrSnuxDmO7U5cHHOf53uNzEn52yo0MWuo16s1OFYxU+sHP/jBKRkz8DeRSCR6kJNTIpEYJBatQdzSRtDlK7KkkVkdo1HTOKS27nxfTXopeXSwlG77XFWu6G6gqiil1kgZHQNVY1Qf4vXKK6U/55xzgC7nEHQbAapIUvPXve51kzaqvBq/DznkkMk51UlVBNWA6DDZGpJVg6Lq4n3aQhHRFUD1VFmjsdrrfS+tWgWdeuk778s+2rop9DnVtjGOcTNFtTaqetDvqtLmFIOZuaqUuS/y3374XcTxNDbQWM2+2Drl9lxUC1X9/en9olrn84fijJnMKZFIDBKzYk6llHWBTwJbAxX438C1wPHApsBNwKtrrXcv5xZzBmf9aOiX4biymJsnGrRbh0BX7timzSYQt16jMRi67eXIvKLhGjoGFVc484NbLiiWhjLvszLZ12hkbh3xbPusZz1r0ubEE08E4FWvehXQORhCxwI+8pGPAF00fuxrWw69zdkEM7fD/RkdAx1P722eLejen/e2H5FdtVkmNXbHTYTWEB1zHMkGZVV+AzFbQst27Vd0GLXfvo/IPFq3C/sajfb2tc2mGu9jLvc+R1M3c3SH0YgftQdllHmaffP000+ftOljlfOJ2TKnDwGn11q3ArYBrgYOAb5Wa90C+Nr470QikVgluF9XglLKo4DvAE+poXEp5Vpg11rrHaWUDYDzaq1bLu8+MLeuBBFtmIWOdNqgoHOI9KcrU1x5W1tLROsC4MoabQPeS32/Xc2gswMtW7YM6M855TNcaSObaLfu++SQWXgu5pw6/PDDga60t9dFGdvwHe8Tt67bfE7KE2X1OllEZJn2W1kduzj2bRFI2/aF6vTlMG8LZsqw4zMcY8e1r8R3G7YTWU0bsCzD7svV5L2VK/7f9JzVU6KdUsbYZjGNbfx2HWMzfF5yySUz+rOQqq88BbgL+OdSyqWllE+WUh4OPKHWegfA+Ofj+y4upexfSllWSlk2lz5ViURiYWM2k9NawHOAj9ZatwN+wQNQ4WqtH6+1bl9r3X4ouwCJRGL4mI1a90TgwlrrpuO/d2E0OW3OAlHrhHRbta5PFj2sVSvi+EjFNXL2ReG3RsW+tLCiLxG9Kon3juqY5ZouvvjiqTZR9WzVCLeyt99++0mb3Xfffer58XqN7m3fYhv7rwuA9+nzzHaM+wqRqs60HtowU3Xuy8ekTF7ftxnSxv9FlSs+DzpDeCyjpXrauiRET3O/FeWJ4+A4+h58ZnyvbaFMr48FDrzevsZYR1U9VW8N/fF6+280wJFHHgn0e6qvbqwyta7W+kPg1lKKE8+LgauAU4H9xsf2A055kLImEonEDMwqtq6Usi0jV4K1gRuBNzKa2E4AngTcAuxTa/3Jcm/C/DMn++qqd8op3XzqtmsbyxVXWlctf8bVz/aurOYtioyjjYtqr4n31hAbx6tlJrKc6KJgJLosoM0PBV2+IJ06+1ZxV3jHIxqZlbeNI4xOrV7nBoN9jyu1TKEvj1DrWOkz4/VtTJno28o3e2gcz/bb74vK93nK2hdXaVEIv6s41m3mhbacVTxmf3ymMXLQOaPqJhDdRxzr1pXCTRWAbbfdFoADDjhg6lnzgdkyp1n5OdVaLwO27zn14gcqWCKRSMwGizYrQR/arecDDzxwck69vS2wGCPl1dvV6eNKKxtqGUIb9gAzbSRxFfU679cXNtLeM25L28aVXsYQQ23aQpUxO6VMr13pV1SoUnliiSmf59a1Y9dXikiZI4Nrw136cmjJDmURPjNmDNCeZ+aAM844Y3JO21tb1DO+j5blxnFs5ZB9R4fcthxY37fTlrBv3wF036f9j8yntesdccQRwHROd88NYcc8sxIkEokFjSXFnERfgONrX/taoMsH7UoV7Rmyqeuvvx6YZlXaIrznimxW7TWxjXYXV88V7er09UP7g2zGlTvavtyN6mN13tv7eF20o7Sl0n2n0XYmm/F6wy9iUK1sStvZdtttNzkni3H1l93E0BKdDZVZOaLjquxDRht36GQ6hr8YchR3BNtgb5lY/C4cR2080QFVxmRftYFFBtmG9jhmfUHOG2644VTfoXv/2r5OOOEEoAtRgWEF9SZzSiQSCxo5OSUSiUFi0eVzmg36DNGnnXYa0Klsbr1G1WfHHXcEuuj5SLt1ilP9UMXoc9RsDcBRDlUMaXhfmaN2Cz+qU8q0om3y1qEwPt9nqI6ouvVdr6qjOhTHqo2bO/bYYwF4y1veMuM+IhqyW1cK1aC4he8zLrjgAqB7P3Gb3X6opsZI/bYwgCpjjL9T5bRvXhPVKjNI2J/YD9XJXXfdFejUwWisVuXzu2oLWMBMk4DXQLfpoDq6ok2HhYRkTolEYpBYksxJRHbhaunKaoR9LK9z/vnnA90qGI2ztpMpafiNISttaIqrcWQDshFZVWQjbY4jV8zomOjq7T37Mki6nd1mLohw9fd+cRXXoC5bbAs3xHvryvDc5z53qg/QsQ9ZQJRDxuM9t9pqqxnXn3322QDsvPPOU/cxvAe6MTefVXTNaJ0f2638OA72UVeCWFLJ96HM0SBveXflts+RCdlHf/rtxW8n3hOmv0u/gy9+8YtAx8oiW0rmlEgkEqsIS5o5RbR2IFf6LbbYYtLGLJFu2VpGCmbaWPpcJly1dXo0JCE627kyt8Ux4/WtQ19fzmxZgX9HxiAbaJ1SYz+8p9dF5iWL0D1AO0q0g9gnjzmOZtiEbsXfc889gelg1pZVymxjP3Q9aG1xOlxCF1LThnjEfreZMPsCqf0Z34doc01FJiyDVg5Z3TbbbDNDDr8rWVJ0jm3dHOI4HH/88QCceuqpwMzMnAsVyZwSicQgsSSdMFcEVxud3d7znvdMzrkymooi2nraYpbaFKIjXJuN0NzPMXBX24ircQyFuPHGG4GZ4Q59KUJcPWUM0cbRrqiRKcgi2ookkZ15vcwvMiZhgGqb7TPa0FoGFm1OMgN/ygC/+tWvTtrsvffeQMfcZITRHqN9zPvEaiNtGXLfQ9yZNIe7P90JjDuN3qfNBQ7duzaI13cXGZis0p1i4bhA9z4c60984hOTczKuIYSmzAbphJlIJBY0cnJKJBKDRKp1DdrxMNYOuuKc0Rgp2uIFqj466EGnYqlGuHUcHfpUERynaCyX2qtiaKCPaoTw3saCxeyOqi2qCDfddNOMZ/hTtSSOi/dSDepL2t/G/2noj+4XOh0aoxhdEWJJrNg2jodjZDktVS1LJMHM/FjxffiOVLkc+6jCui1vHzWoR5XecehzanUcfOe+6zievo+2cER04LX/Rx11FABnnnnmjH6kWpdIJBJzgGRODfq218Wzn/1soGNQfQ6W0RgL3RYwzMzl89SnPnXGM1zp23CJ+Lw2FCMapB1fmYIsJ5Zd8vfWNQK61VvjcpvJEbqtcvvq/WLYhmxMFmCbyEraMuYxy0ObKUADcnTt0BDuOPj8OGaOeV8ZrbbMkgbp+F68d5ttMxrv2zCYvmwCjp9jF5ms79x359+RPX74wx8G4KqrrgJm5j9fSEjmlEgkFjTSCbPBihzXLr/8cgDe//73A3DQQQdNzrVFNVdUstyVui1KGY+1YTDQ2Y+UURtLXEVdvdtQjGgPkoW0FT2ivG0xzSij9pY20DXaYXSQdPWXFUVm2Wb2jLY8WYQOlTIoy6NHyErceo9OkNq6tBVFBtiGEX35y18G4OCDD57xjLaaTXQlcGzsmy4W8TrbK0dkmVZEOfnkk4GO3V1zzTWTNn0FQxc7kjklEolBYulMww8QK6qBJhs49NBDJ+fe9ra3AR27cTWO6Tfa3RjPxaolrrA+SzsXdFVTXFnbvOXQreLaeGQ+MZNlyw4ju1Mmr3OFj86TrYOmDquR+fi755Qn7kA5Vo5n7EeblsUxiizPcBftSdqpYoiKz7fPMUSmrfHnWMfx8N5eF1mZUG531CKTbZ1zZc1xPK0C9J3vfAfoxjU6xw4pk+VcIZlTIpEYJHJySiQSg0SqdfeDPhotxY7b0ocffjgAL37xqJSfkfbRdUK67vVmWYxqhG1UI2Kpco3U0Vmxvd4t78022wzoYtyiK4FqVGtgh5mFEVR9orG7baOROqohtrH/Oj/G/vhcjb1RZVOtUy1SvYqR+qLNshDVQ69bUel336NZJqLbgAZ1t/5V2aLjq8/z+fH9KK/qtmrze9/73kkb1fU22+VSUuH6kMwpkUgMEsmcVgJ9K9s555wDdDl59t1338k5V1tDXFyx431kOv6M7MywDFdojcvRWc/V1xVap8W4KhtC4vZ+NGTLwlp22FdqXFYhS4oFJ5VVR0/ZgVkeodtCt/+RZbZlkmR+Mfe2rCRuy0OXUxzgec97HtCxm8iqZIP2X7eF2A+PtRsN8ZmGrzjGMUvmSSedBHSOrr7XFZUMS4yQzCmRSAwSGb6yitGGv8QtY8MlzON02GGHTbWFzq7kdnhkLDr3aT+RRUTHPO0lLeOJTpSyEW1ecXvf61ubTyw0KfuQnfUVB21DU2Rrn/vc5yZtDKr2nK4A0LEimYb3WZENUMQcWH/3d38HdEVTf+u3fmtyTrlvvvlmoBuPrbfeeoYcOsMaZBwZnOdkR31ZR1t7Y5+LylJBhq8kEokFjZycEonEIJEG8VWMlqLHGCy3021jytl99tln0qb1JI7Gbq/TqNynTqmGqFpo9I5yqFbqbhBVPn/3nqpacXtc73FVFc9FV4K20INqZjSIn3HGGUCnRr385S+fnPM61Tr7EVU/1ds2RvAb3/jGpI2FKiwCEDcYNFx7zJTKUa0zra9j5jPimDlWfepZu8Eglpoq92CQzCmRSAwSaRCfR7iVHdnEn/7pnwKd0180vMoQNPhasDLC92keIo3d0bD+7ne/G+iyK8Rk+zI3XQBkRbGoY+uEqYtEzMekkdutd5lG/N4sUa6R+kUvetEMOXRBsO+xGIS5jSyuqWG7r1hqX5ZLWZD9kOVEVtRu86/o/0uyodkhDeKJRGJBI5nTPMKx78v5ZPltw2Cgs5/IAmQF0dYjZDoyr2hHkU1pa+nL/a1dSXliXikZkvYt3Q+iu4F98pj3jWEfbstfd911AOy0006Tc9tuuy3Q2Z7MrKlTI3RhM7o79I1DW2p9Nq4I99c+sXJI5pRIJBY0kjkNDG3O7uhQqP1GNiKTeuYznzlpY1FOmZOMJTpaeh+dDi+66KLJOdmHDp/eL+ZIikwvytq3W6f83u/EE0+ctNGeI0s74YQTJue0p2lHcvex73tdirmOFjJWKXMqpfxJKeXKUsoVpZRjSykPLaVsVkq5qJRyfSnl+FLKTE6dSCQSDxL3OzmVUjYC3g5sX2vdGlgTeC1wOPDBWusWwN3Am1anoIlEYmnhftW68eR0IbAN8DPgZOAo4F+AJ9Za7y2lPB94X611txXdK9W6+0erosT34+9tnFZ0sNx5552BLq+UhvA47uZoMpF/jKI3Y4Jq4Ktf/WoAdtlll0kbVTUdIr1fVP10RdCJUsfIWCrLNqpsUS20/6mqLT6sMrWu1no7cARwC3AH8FPgYuCeWqt5I24DNuq7vpSyfyllWSll2UKpSJpIJOYfs2FO6wEnAa8B7gE+P/77vbXWzcdtNgG+Umt91orulcxp5bA8w29faWudFnUXiAZxYVbImJtIg7zuCn2lpdqMj4aRxCIKrWNja0Rv5W6RjGnxYlUaxF8CfL/Welet9VfAF4AXAOuWUozN2xj4wYOWNpFIJBrMJvD3FmDHUsrDgF8CLwaWAecCewPHAfsBp6wuIRMjLI9NxOOtY6fb9H0spc0gGe+lXUsmFVlRe69Y/krMJrtjsqPEijAbm9NFwInAJcDl42s+DhwMHFhKuQF4DPCp1ShnIpFYYkgnzCWCvveczCUxH8jwlUQisaCRk1MikRgkMhPmEkGqcImFhmROiURikMjJKZFIDBI5OSUSiUEiJ6dEIjFI5OSUSCQGiZycEonEIJGTUyKRGCRyckokEoNETk6JRGKQyMkpkUgMEjk5JRKJQSInp0QiMUjk5JRIJAaJnJwSicQgkZNTIpEYJHJySiQSg0ROTolEYpDIySmRSAwSOTklEolBIienRCIxSOTklEgkBomcnBKJxCCRk1MikRgkcnJKJBKDRE5OiURikMjJKZFIDBKl1jp3DyvlLuAXwI/n7KGrBo9l4ckMC1PulHluMJ8yP7nW+rj7azSnkxNAKWVZrXX7OX3oSmIhygwLU+6UeW6wEGROtS6RSAwSOTklEolBYj4mp4/PwzNXFgtRZliYcqfMc4PByzznNqdEIpGYDVKtSyQSg0ROTolEYpCYs8mplLJ7KeXaUsoNpZRD5uq5DxSllE1KKeeWUq4upVxZSnnH+Pj6pZSzSinXj3+uN9+ytiilrFlKubSU8qXx35uVUi4ay3x8KWXt+ZYxopSybinlxFLKNePxfv4CGec/GX8bV5RSji2lPHRoY11KOaaUcmcp5YpwrHdsywgfHv/f/G4p5TnzJ3mHOZmcSilrAh8Bfgd4BvD7pZRnzMWzHwTuBQ6qtT4d2BH447GshwBfq7VuAXxt/PfQ8A7g6vD34cAHxzLfDbxpXqRaPj4EnF5r3QrYhpHsgx7nUspGwNuB7WutWwNrAq9leGP9aWD35tjyxvZ3gC3G//YHPjpHMq4YtdbV/g94PnBG+PtQ4NC5ePYqkP0U4KXAtcAG42MbANfOt2yNnBsz+uBeBHwJKIw8gNfqewfz/Q94FPB9xpsy4fjQx3kj4FZgfWCt8VjvNsSxBjYFrri/sQU+Bvx+X7v5/DdXap0vVNw2PjZolFI2BbYDLgKeUGu9A2D88/HzJ1kvjgT+DLhv/PdjgHtqrfeO/x7amD8FuAv457Eq+slSysMZ+DjXWm8HjgBuAe4AfgpczLDHWixvbAf5/3OuJqfSc2zQPgyllEcAJwHvrLX+bL7lWRFKKXsCd9ZaL46He5oOaczXAp4DfLTWuh2jmMtBqXB9GNtpXglsBmwIPJyRWtRiSGN9fxjktzJXk9NtwCbh742BH8zRsx8wSikPYTQx/Uut9Qvjwz8qpWwwPr8BcOd8ydeDnYC9Sik3AccxUu2OBNYtpaw1bjO0Mb8NuK3WetH47xMZTVZDHmeAlwDfr7XeVWv9FfAF4AUMe6zF8sZ2kP8/52py+jawxXhHY21GBsRT5+jZDwillAJ8Cri61vqBcOpUYL/x7/sxskUNArXWQ2utG9daN2U0tufUWl8HnAvsPW42NJl/CNxaStlyfOjFwFUMeJzHuAXYsZTysPG3otyDHeuA5Y3tqcC+4127HYGfqv7NK+bQOLcHcB3wPeDd821sW4GcOzOitN8FLhv/24ORDedrwPXjn+vPt6zLkX9X4Evj358CfAu4Afg8sM58y9fIui2wbDzWJwPrLYRxBg4DrgGuAD4LrDO0sQaOZWQT+xUjZvSm5Y0tI7XuI+P/m5cz2omc93HO8JVEIjFIpId4IpEYJHJySiQSg0ROTolEYpDIySmRSAwSOTklEolBIienRCIxSOTklEgkBon/DwND6aEOY1H/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Scan image\")\n",
    "plt.imshow(np.squeeze(cis_data[4][0][0])[:,:,42], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_model(path, finetune=True, up_to=7):\n",
    "    model = load_model(path)\n",
    "    model.load_weights(path)\n",
    "    if finetune:\n",
    "        for layer in model.layers[:up_to]:\n",
    "            layer.trainable = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv3D)              (None, 94, 112, 94, 64)   1792      \n",
      "_________________________________________________________________\n",
      "Pool_1 (MaxPooling3D)        (None, 31, 37, 31, 64)    0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 31, 37, 31, 64)    0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv3D)              (None, 29, 35, 29, 64)    110656    \n",
      "_________________________________________________________________\n",
      "Pool_2 (MaxPooling3D)        (None, 9, 11, 9, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 9, 11, 9, 64)      0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv3D)              (None, 7, 9, 7, 64)       110656    \n",
      "_________________________________________________________________\n",
      "Conv_4 (Conv3D)              (None, 5, 7, 5, 64)       110656    \n",
      "_________________________________________________________________\n",
      "Pool_4 (MaxPooling3D)        (None, 1, 2, 1, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1, 2, 1, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 333,889\n",
      "Trainable params: 333,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# load model weights\n",
    "model_path = \"/analysis/share/Ritter/models/fabi/ADNI/pretraining_paper/model.h5\"\n",
    "model = init_model(model_path, finetune=False, up_to=None)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_weights(model):\n",
    "    # Visualize weights\n",
    "    W = model.layers[0].get_weights()[0]\n",
    "    W = np.squeeze(W)[:,:,2]\n",
    "    print(\"W shape : \", W.shape)\n",
    "\n",
    "    print(\"Weights mean {}\".format(W.mean()))\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.title('conv1 weights')\n",
    "    plt.imshow(make_mosaic(W, 2, 2), cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy.ma as ma\n",
    "def make_mosaic(imgs, nrows, ncols, border=1):\n",
    "    \"\"\"\n",
    "    Given a set of images with all the same shape, makes a\n",
    "    mosaic with nrows and ncols\n",
    "    \"\"\"\n",
    "    nimgs = imgs.shape[0]\n",
    "    imshape = imgs.shape[1:]\n",
    "    \n",
    "    mosaic = ma.masked_all((nrows * imshape[0] + (nrows - 1) * border,\n",
    "                            ncols * imshape[1] + (ncols - 1) * border),\n",
    "                            dtype=np.float32)\n",
    "    \n",
    "    paddedh = imshape[0] + border\n",
    "    paddedw = imshape[1] + border\n",
    "    for i in range(nimgs):\n",
    "        row = int(np.floor(i / ncols))\n",
    "        col = i % ncols\n",
    "        \n",
    "        mosaic[row * paddedh:row * paddedh + imshape[0],\n",
    "               col * paddedw:col * paddedw + imshape[1]] = imgs[i]\n",
    "    return mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_weights(model):\n",
    "    session = K.get_session()\n",
    "    for layer in model.layers: \n",
    "        if hasattr(layer, 'kernel_initializer'):\n",
    "            layer.kernel.initializer.run(session=session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained model layer 1 weights:\n",
      "W shape :  (3, 3, 64)\n",
      "Weights mean -0.003789090784266591\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random model layer 1 weights:\n",
      "W shape :  (3, 3, 64)\n",
      "Weights mean -0.0008154722745530307\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIQAAABrCAYAAAAGj1lyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAHUxJREFUeJzt3Xm41XW1x/HPkkEE9YIKMioiR1EsFJFbQsXF61VMpJ4UUAxNDZFQVBJFHAKzsOuD4awVDj3OiEpmKSapJDI7YGAXGWSQQUTAcELW/WP/qOPh8F0/YtjntN+v5+Fh770Wa3/3Od/9Gxa/wdxdAAAAAAAAKB27FXsAAAAAAAAA2LVoCAEAAAAAAJQYGkIAAAAAAAAlhoYQAAAAAABAiaEhBAAAAAAAUGJoCAEAAAAAAJQYGkIAAAA7kZndaWZX58y918x+urPHBAAAQEMIAACUDDNrYmbjzWyZmbmZtdzZ7+nu/d39uh1RKxtz6x1RCwAAlDYaQgAAoJRskvRHSd8r9kAAAACKiYYQAAAoGjNrYWbjzGyVma02s1uz13czs6vMbJGZrTSz+83sP7JYy+xImbPM7F0ze9/MhmWxpmb2sZntU+49jspyarn7Cne/XdK0HGP7gZn9rtzzeWb2aLnni83syOxxGzObYGYfmNnbZtazXN6XTgMzsyFm9l52lNJ5lRz108DMfm9m681sipkdnP27l7L462b2kZn1MrP9zOxpM/swe++XzYztOwAAEGKDAQAAFIWZ1ZD0tKRFklpKaibp4Sx8dvbnvyS1krSnpFsrlOgs6VBJx0m6xswOc/dlkibry0cAnSFprLt/vo1DfFHSN7LmVBNJtSR1ysa+eUxvmFk9SRMkPSipkaTTJd1uZm0r+cwnSrpU0n9Lai3pW5W87+mShktqIGmepOslyd2/mcXbufue7v6IpMGSlkhqKGl/SVdK8m38nAAAoATREAIAAMXSUVJTSZe5+9/d/RN3n5TF+kga5e7z3f0jSUMl9TazmuX+/XB3/9jdX5f0uqR22esPqtBUkZmZpN7Za9vE3edLWi/pSBUaN89KWmpmbbLnL7v7JkknS1ro7ve4+0Z3nynpcUmnVlK2p6R73P0td9+gQuOnonHuPtXdN0p6IHv/rflcUhNJB7r75+7+srvTEAIAACEaQgAAoFhaSFqUNT4qaqrCkUObLZJUU4WjYDZbXu7xBhWO2JGksZK+bmZNJX1ThSNmXv4Xx/iipC5ZnRcl/VmFZtC3sueSdKCk/8xO2/rQzD5UoaHVeCufa3G554srydna56rM/6pwFNFzZjbfzK6IPhAAAIBU2LACAAAohsWSDjCzmpU0hZap0GjZ7ABJGyWtkNQ8VdTdPzSz51Q4GucwSQ9tx1EzL0rqLukgST+TtLnZ83X98xS2xZJedPfjc9R7T18ef4t/cVySJHdfr8JpY4OzU9Qmmtk0d//T9tQFAAD//jhCCAAAFMtUFRokI82snpnVMbNOWewhSZeY2UFmtqcKzZhHtnI0UWUelNRXhWsJfel0MTOrI2n37Onu2fOteVGF6xjt4e5LVDjS6ERJ+0qaleU8LekQM/u+mdXK/hxjZodVUu9RST8ws8PMrK6ka3J+ns1WqHBNpc2f5WQza52dGrdO0hfZHwAAgCQaQgAAoCjc/QsVjr5pLeldFS6O3CsLj5H0W0kvSVog6RNJF25D+fGSyiStyK4xVN7Hkj7KHs/Nnm9tjH/Lcl/Onq+TNF/SX7Lxbz5K539UuFbRMhVO+bpB/2w6la/3B0k3S5qowqlek7PQpzk/108k3ZedmtYz+4zPZ2OcLOl2d/9zzloAAKCEGdcdBAAAKI7sKKLZknbfhqOfAAAAthtHCAEAAOxCZvZdM6ttZg1UOJLodzSDAADArkZDCAAAYNc6X9IqSe+ocL2fC4o7HAAAUIo4ZQwAAAAAAKDEcIQQAAAAAABAialZrDc2s/DQpKZNmybjjRs3Dt9nzZo1Yc66deuS8d133+ImIVtYuXJlmLPffvsl43//+9/DGnvvvXcyvv/++4c13nvvvTCnfv36yfj8+fPDGgcffHCY8+mn6ZuqLF26NKzxxRfx3XU///zzZLxWrVphjZYtW4Y5kTzvs2rVqjAnOrJv9erVYY0jjzwyzFm2bFkyvn79+rBGnu9pNK8/+eSTsEbNmunF2dq1a8MajRo1CnOin32e98nz/dlnn32S8d12i/v5eX720XfjnXfeCWscccQRYc5f//rXZDzPWKPfsSTtscce2zUOSWrYsGGY88EHHyTjdeqk7mJe0KxZs2R8w4YNYY3ly5eHOdG83rRpU1ijSZMm2z2WPO+TZxlZo0aNZLxevXphjWi9L8XzIPruSPnW61FOnnVctC6VpH333TcZz7NtkGdeR++Tp0bt2rWT8TzbBnm+P82bN0/G82z/5VmmRN/BPPMx+rlK8VzJs37Kc+ZA9Pv56KOPknEp3/IgWubnmfd5fofR+jTP+jb6PAceeGBYI8+2W7RvlOe7kWffaEds8y5YsCDMadCgQTIebQtJ+bYRo/20PMulaFtVir8/eT5PtI6T4uV13bp1wxp55lu075pnORt9f/Isc/Lsb0TbKXmWs3vttVeYs3jx4mQ8z/IimvdSvC2TZ529du3a99093Kgt2iljZuZmlsz5yU9+kowPHTo0fJ/HHnsszJkwYUIyXlZWFta46aabwpzzzz8/GZ86dWpY47jjjkvGL7744rDGT3/60zCnR48eyfjpp58e1hg3blyYE+1sXnXVVWGNPCu2aEclWsFK0pgxY8KcaIMgz07vXXfdFeZEG32//e1vwxp5mpgjRoxIxl988cWwxpAhQ8KcaF6//fbbYY1opfX000+HNS68ML6jdbQT+Mwzz4Q1evXqFeb06dMnGc+z03v55ZeHOdHG42mnnRbWyLND1KFDh2T8xz/+cVgjT8Oubdu2yXj79u3DGhdcEF/OJfqO5WmSRcviWbNmhTVGjhwZ5lx00UXJeJ6mxZVXXhnm3Hjjjcn4xx9v9c7u/5DndxxtsHXq1Cms8eyzz4Y5/fv3T8ajhrkkTZkyJcyZMWNGMh41H6V8jduzzjorGb/uuuvCGocddliY07dv32T8kEMOCWscdNBByfiwYcPCGjNnzgxzfv7znyfjef5j6+ijjw5zBgwYkIxPnDgxrHHmmWeGOdH2UJ55n6fR2aJFi2T8L3/5S1gjzw5etDzIM+9btWoV5uy5557JeJ6mUrR8y7Ntd//994c511577XbFJenRRx8Nc6Jt3jwNvbPPPjvMibYx8uxvzJ07N8y55ZZbkvE8+3onnHBCmBM1KfN8j/M0JaLth2ibS8q3X9OvX79k/LXXXgtrRM22PP/p8fzzz4c5V199dTIe7e9LUteuXcOcaJsq+o9JKd9+wDHHHJOMX3/99WGN3/3udzPcPZwMuU4ZM7MTzextM5tnZldUEt/dzB7J4lPMrGWeugAAAAAAANj1woaQmdWQdJukbpIOl3S6mR1eIe1cSWvcvbWkm1S4hSoAAAAAAACqoDxHCHWUNM/d57v7Z5IellTxfKIeku7LHo+VdJxF54MBAAAAAACgKPI0hJpJKn/1pCXZa5XmuPtGSWslbXH1OzPrZ2bTzWz6vzZcAAAAAAAAbK88dxmr7EifileizpMjd79b0t1SvruMAQAAAAAAYMfLc4TQEknlbyfQXFLFW2v8I8fMakr6D0nxbTEAAAAAAACwy+VpCE2TVGZmB5lZbUm9JY2vkDNe0ub7mZ4q6QUv1v3sAQAAAAAAkGR5+jZmdpKkX0qqIWmMu19vZiMkTXf38WZWR9JvJR2lwpFBvd19fqpm/fr1vXPnzsn3HT16dDJ+8MEHh2Pv2bNnmPPrX/86GX/yySfDGp06dQpzbrvttmQ8+nlI0uDBg5PxNm3ahDXmz0/+aiRJDz/8cDJ+yy23hDVWrVoV5tStWzcZf+ONN8IagwYNCnNuuCF947s8Yz377LPDnGHDhiXja9asCWu88MILYU7jxo2T8blz54Y1ataMzxjt1atXMl6jRo2wxksvvRTmPP7448n4I488EtZ45plnkvE333wzrDFu3Lgw58QTT0zGP/ggPjjy1VdfDXNWrFiRjA8cODCscdddd4U50Zy95JJLwhrTpk0Lc7p165aMN2tW8dJ0W1q6dGmY06VLl2T80EMPDWvkmW/Lly9PxkeMGBHWaNWqVTKeZ87uu+8Wl+vbwkMPPZSMf+c73wlrbNq0KcyJvoM9elS8H8WWGjRoEOZ89tlnyXj03ZGkDRs2hDlXX311Mp5n/bRw4cIwZ8iQIcn4z372s7BGnmVxtN4oKysLa+yzzz5hTrRu2WOPPcIab7/9djIefXck6amnngpzot/PlClTwhoXXnhhmHPPPfck49F6RZLOOOOMMCf6HY8dOzassWTJkjDnjjvuSMZr164d1pg5c2aY87e//S0ZnzNnTlijY8eOYc7777+fjLdr1y6sMWrUqGS8UaNGYY1JkyaFOSeccEIy3rZt27BG9PuT4nXL6tWrwxrdu3cPc6J9sDzfjXfeeSfM+fzzz5PxkSNHhjXy7FMOGDAgGR8+fHhY46233gpzov2a3XaLj/nI8x18+eWXk/Hjjz8+rNGvX79kPM+6p0+fPmHOxo0bk/G77747rNGiRYswJ9oXf+6557a7hiTdeeedyfjhh1e86fuW+vfvP8PdO0R5ea4hJHd/RtIzFV67ptzjTySdlqcWAAAAAAAAiivPKWMAAAAAAAD4N0JDCAAAAAAAoMTQEAIAAAAAACgxNIQAAAAAAABKDA0hAAAAAACAEkNDCAAAAAAAoMSYuxfljRs3buxnnnlmMmfKlCnJeM+ePcP3adGiRZjz7rvvJuOtW7cOa5xyyilhTqNGjZLxhQsXhjXOOeecZHz06NFhjSuuuCLMefLJJ5Pxk08+Oaxx8cUXhzmLFy9OxocPHx7WaNOmTZhz9NFHJ+NPPfVUWOOjjz4Kc2bNmpWM33jjjWGN/v37hzm9evVKxgcNGhTWWLJkSZiz9957J+NffPFFWOOCCy4Ic9avX5+M5xnrxIkTk/E8c6lu3bphTu3atZPxOnXqhDV69+4d5kydOjUZ/+UvfxnWOP/888OcaJly/fXXhzXWrVsX5nzwwQfJeJcuXcIajz76aJizfPnyZPzYY48Na0TzXpI2bNiQjE+bNi2s0bJly2Q8z/Li+eefD3NWr16djA8dOjSs8dhjj4U50XqjT58+YY088+DZZ59Nxps0aRLWGDFiRJgTzaWuXbuGNe69994w54knnkjG86xLx4wZE+b8/ve/T8Y/+eSTsEb79u3DnHbt2iXj5557blgj+n517tw5rPHKK6+EOX379k3Go5+ZJE2ePDnMWbVqVTI+Z86csMavfvWrMOekk05KxufNmxfWWLNmTZhz1llnJeM9evQIa3zrW98Kcw455JBkvH79+mGNPOvkhg0bJuMXXXRRWOPQQw9NxqM5LUnDhg0Lcx588MFk/Ec/+lFY47vf/W6YE22XRdsoUr51WLTcOfDAA8Ma0XaZJA0YMCAZz7Nv9Pjjj4c50c82zzph8ODBYc7MmTOT8TzbZbNnzw5zBg4cmIw/8MADYY0bbrghGb/88svDGtGyTZLKysqS8T//+c9hjTz7LNH+RJ6f/TXXXBPmNG3aNBnPs+22atWqGe7eIcrjCCEAAAAAAIASQ0MIAAAAAACgxNAQAgAAAAAAKDE0hAAAAAAAAEoMDSEAAAAAAIASEzaEzKyFmU00szlm9paZbXH7IjPrYmZrzey17E986WwAAAAAAAAURc0cORslDXb3mWa2l6QZZjbB3f9aIe9ld4/vRQ4AAAAAAICiCo8Qcvf33H1m9ni9pDmSmu3sgQEAAAAAAGDnMHfPn2zWUtJLko5w93XlXu8i6XFJSyQtk/Rjd3+rkn/fT1I/STrggAOOXrRo0XYMHQAAAAAAAOWZ2Qx37xDl5b6otJntqULT5+LyzaDMTEkHuns7SbdIerKyGu5+t7t3cPcODRs2zPvWAAAAAAAA2IFyNYTMrJYKzaAH3H1cxbi7r3P3j7LHz0iqZWb77dCRAgAAAAAAYIfIc5cxk/QbSXPcfdRWchpneTKzjlnd1TtyoAAAAAAAANgx8txlrJOk70t608xey167UtIBkuTud0o6VdIFZrZR0seSevu2XJwIAAAAAAAAu0zYEHL3SZIsyLlV0q07alAAAAAAAADYeXJfVBoAAAAAAAD/HmgIAQAAAAAAlBgaQgAAAAAAACUmz0Wld4ply5Zp+PDhyZzsxmVb1alTp/B9evbsGeY89thjyfiYMWPCGm+99VaYM27cuGT80ksvDWu0adMmGW/WrNl2j0OSFixYkIy//vrrYY2RI0eGOZMnT07GJ02aFNZo2LBhmDNv3rxkvFGjRmGNjh07hjmnnXZaMl6zZvyVGzRoUJhz6qmnJuNXXXVVWOP2228Pc+rXr5+MT506NazRvn37MGfUqEpvYPgPEydODGt8+umnyfj48ePDGmVlZdud07x587DGzTffHObMnj07GR8xYkRYY7/99gtz7rjjjmR87NixYY3LLrsszOnevXsyft5554U1Zs2aFeZcdNFFyfhXvvKVsMaaNWvCnOuuuy4Zb9WqVVgjWgdOnz49rHHttdeGOZdcckkyfvzxx4c1rr766jAnWm+0bds2rNGhQ4cwZ+nSpcn4ueeeG9b43ve+F+asWrUqzAEAAKjOOEIIAAAAAACgxNAQAgAAAAAAKDE0hAAAAAAAAEoMDSEAAAAAAIASQ0MIAAAAAACgxNAQAgAAAAAAKDE0hAAAAAAAAEoMDSEAAAAAAIASY+5elDeuVauWN2jQIJlzyy23JOMLFy4M32fatGlhTuvWrZPxyZMnhzXOPvvsMOerX/1qMt6uXbuwRrdu3ZLx559/PqyxbNmyMGfw4MHJ+MSJE8MaixYtCnN++MMfJuMtW7YMa9SqVSvMOe+885LxX/ziF2GNevXqhTl33XVXMt65c+ewxp133hnm9O3bNxnv06dPWOO+++4Lc6ZMmZKMH3DAAWGNZs2ahTmnnHJKMp7nZ19WVpaMr1y5MqwxevToMKdr167J+Le//e2wxm67xb34PN/TSJ6fW506dZLxY489NqwRLUMlafbs2cl4NAckqXv37mHO9o5DkgYOHBjmPPjgg8n4+PHjwxpnnHFGMh6tAyVp3333DXNuvfXWZDxaPkpSnm2F6dOnJ+PRd0eSjjrqqDDnsssuS8ajZYEkjRs3Lszp2bNnmAMAAFAVmdkMd+8Q5eU6QsjMFprZm2b2mpltscVnBTeb2Twze8PM2v8rgwYAAAAAAMDOV3Mbcv/L3d/fSqybpLLsz39KuiP7GwAAAAAAAFXMjrqGUA9J93vBq5Lqm1mTHVQbAAAAAAAAO1DehpBLes7MZphZv0rizSQtLvd8Sfbal5hZPzObbmbTN23atO2jBQAAAAAAwHbLe8pYJ3dfZmaNJE0ws7nu/lK5uFXyb7a4AqW73y3pbqlwUeltHi0AAAAAAAC2W64jhNx9Wfb3SklPSOpYIWWJpBblnjeXtP23yAEAAAAAAMAOFzaEzKyeme21+bGk/5FU8b694yX1ze429jVJa939vR0+WgAAAAAAAGy3PKeM7S/pCTPbnP+gu//RzPpLkrvfKekZSSdJmidpg6QfREXr1Kmjtm3bJnMGDBiQjF922WXh4IcMGRLmHHPMMcn44sWLk3FJmjt3bpjz4YcfJuNLly4Na7zxxhvJeLdu3cIa7dq1C3NOOOGEZPydd94Ja3Tq1CnMue+++5LxcePGhTV22y0+0G327Io9zC979913wxq9evUKc1asWJGMT5kyJazx/e9/P8wZOXJkMj5x4sSwRp7Pc/vttyfjzz33XFjj4YcfDnOi73rXrl3DGuecc06YExkzZkyYU6NGjWR88uTJYY3GjRuHOd27d0/GFyxYENb4xje+EeZMmjQpGX/hhRfCGqNHjw5zDj744GQ8zzI0j1deeSUZr1+/flhj4MCBYc4VV1yRjN90001hjWh5cemll4Y1Zs2aFebstddeyfioUaPCGtF8lKRWrVol4xMmTAhr5Fnfrl+/PhmvU6dOWOO2224LcwAAAP7dhQ0hd58vaYsOQtYI2vzYJf1oxw4NAAAAAAAAO8OOuu08AAAAAAAAqgkaQgAAAAAAACWGhhAAAAAAAECJoSEEAAAAAABQYmgIAQAAAAAAlBgaQgAAAAAAACWGhhAAAAAAAECJMXcvzhubrZK0qMLL+0l6vwjDAf5VzFlUN8xZVDfMWVQ3zFlUN8xZVDfM2diB7t4wSipaQ6gyZjbd3TsUexxAXsxZVDfMWVQ3zFlUN8xZVDfMWVQ3zNkdh1PGAAAAAAAASgwNIQAAAAAAgBJT1RpCdxd7AMA2Ys6iumHOorphzqK6Yc6iumHOorphzu4gVeoaQgAAAAAAANj5qtoRQgAAAAAAANjJaAgBAAAAAACUmCrREDKzE83sbTObZ2ZXFHs8QEVm1sLMJprZHDN7y8wGZa/vY2YTzOz/sr8bFHusQHlmVsPMZpnZ09nzg8xsSjZnHzGz2sUeI7CZmdU3s7FmNjdb3n6d5SyqMjO7JNsumG1mD5lZHZazqErMbIyZrTSz2eVeq3S5agU3Z/tkb5hZ++KNHKVqK3P2f7NtgzfM7Akzq18uNjSbs2+b2QnFGXX1VfSGkJnVkHSbpG6SDpd0upkdXtxRAVvYKGmwux8m6WuSfpTN0ysk/cndyyT9KXsOVCWDJM0p9/wGSTdlc3aNpHOLMiqgcqMl/dHd20hqp8LcZTmLKsnMmkm6SFIHdz9CUg1JvcVyFlXLvZJOrPDa1par3SSVZX/6SbpjF40RKO9ebTlnJ0g6wt2/KulvkoZKUrY/1ltS2+zf3J71F5BT0RtCkjpKmufu8939M0kPS+pR5DEBX+Lu77n7zOzxehV2UpqpMFfvy9Luk/Sd4owQ2JKZNZf0bUm/zp6bpK6SxmYpzFlUGWa2t6RvSvqNJLn7Z+7+oVjOomqrKWkPM6spqa6k98RyFlWIu78k6YMKL29tudpD0v1e8Kqk+mbWZNeMFCiobM66+3PuvjF7+qqk5tnjHpIedvdP3X2BpHkq9BeQU1VoCDWTtLjc8yXZa0CVZGYtJR0laYqk/d39PanQNJLUqHgjA7bwS0lDJG3Knu8r6cNyK1SWt6hKWklaJeme7DTHX5tZPbGcRRXl7ksl3SjpXRUaQWslzRDLWVR9W1uusl+G6uAcSX/IHjNnt1NVaAhZJa/5Lh8FkIOZ7SnpcUkXu/u6Yo8H2BozO1nSSnefUf7lSlJZ3qKqqCmpvaQ73P0oSX8Xp4ehCsuuu9JD0kGSmkqqp8IpNxWxnEV1wXYCqjQzG6bCpTwe2PxSJWnM2W1QFRpCSyS1KPe8uaRlRRoLsFVmVkuFZtAD7j4ue3nF5kNps79XFmt8QAWdJJ1iZgtVOBW3qwpHDNXPTm2QWN6ialkiaYm7T8mej1WhQcRyFlXVf0ta4O6r3P1zSeMkHSuWs6j6trZcZb8MVZaZnSXpZEl93H1z04c5u52qQkNomqSy7I4MtVW4KNT4Io8J+JLs2iu/kTTH3UeVC42XdFb2+CxJT+3qsQGVcfeh7t7c3VuqsFx9wd37SJoo6dQsjTmLKsPdl0tabGaHZi8dJ+mvYjmLqutdSV8zs7rZdsLmOctyFlXd1par4yX1ze429jVJazefWgYUk5mdKOlySae4+4ZyofGSepvZ7mZ2kAoXRJ9ajDFWV/bP5loRB2F2kgr/c11D0hh3v77IQwK+xMw6S3pZ0pv65/VYrlThOkKPSjpAhQ3D09y94oX7gKIysy6SfuzuJ5tZKxWOGNpH0ixJZ7r7p8UcH7CZmR2pwkXQa0uaL+kHKvznFctZVElmNlxSLxVOYZgl6TwVrl/BchZVgpk9JKmLpP0krZB0raQnVclyNWts3qrC3Zo2SPqBu08vxrhRurYyZ4dK2l3S6iztVXfvn+UPU+G6QhtVuKzHHyrWxNZViYYQAAAAAAAAdp2qcMoYAAAAAAAAdiEaQgAAAAAAACWGhhAAAAAAAECJoSEEAAAAAABQYmgIAQAAAAAAlBgaQgAAAAAAACWGhhAAAAAAAECJ+X+Klbu16mikmAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize weights\n",
    "print(\"Pre-trained model layer 1 weights:\")\n",
    "visualize_weights(model)\n",
    "model_untrained = load_model(model_path)\n",
    "reset_weights(model_untrained)\n",
    "print(\"Random model layer 1 weights:\")\n",
    "visualize_weights(model_untrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 96, 114, 96)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split training set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabiane/anaconda2/envs/postal/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 7s 295ms/step - loss: 0.9679 - acc: 0.5034 - val_loss: 0.8490 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.56000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial0-improvement-BEST.hdf5\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 4s 158ms/step - loss: 0.9621 - acc: 0.5266 - val_loss: 0.8421 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.56000\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 4s 158ms/step - loss: 0.9226 - acc: 0.4034 - val_loss: 0.8601 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.56000\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 4s 158ms/step - loss: 0.9327 - acc: 0.4698 - val_loss: 0.8598 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.56000\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 4s 158ms/step - loss: 0.9098 - acc: 0.5398 - val_loss: 0.8245 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.56000\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 0.8888 - acc: 0.4434 - val_loss: 0.8765 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.56000\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 4s 158ms/step - loss: 0.9485 - acc: 0.3834 - val_loss: 0.8145 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.56000\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.9209 - acc: 0.4734 - val_loss: 0.8118 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.56000\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8415 - acc: 0.4734 - val_loss: 0.8069 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.56000\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 0.8228 - acc: 0.5366 - val_loss: 0.8652 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.56000\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 0.8035 - acc: 0.5334 - val_loss: 0.8170 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.56000\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 4s 175ms/step - loss: 0.8288 - acc: 0.4934 - val_loss: 0.8238 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.56000\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 0.7862 - acc: 0.5634 - val_loss: 0.8565 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.56000\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 0.8005 - acc: 0.5398 - val_loss: 0.7519 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.56000 to 0.72000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial0-improvement-BEST.hdf5\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.7485 - acc: 0.5898 - val_loss: 0.7203 - val_acc: 0.6400\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.72000\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 0.7582 - acc: 0.6166 - val_loss: 0.6851 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.72000\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.7584 - acc: 0.6267 - val_loss: 0.6771 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.72000\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.7150 - acc: 0.7199 - val_loss: 0.6542 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.72000\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.6637 - acc: 0.7399 - val_loss: 0.6473 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.72000\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 0.6268 - acc: 0.7635 - val_loss: 0.6058 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.72000\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.6003 - acc: 0.7367 - val_loss: 0.6106 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.72000\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.5800 - acc: 0.8167 - val_loss: 0.5709 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.72000\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.5108 - acc: 0.8868 - val_loss: 0.5605 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.72000 to 0.76000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial0-improvement-BEST.hdf5\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 0.5363 - acc: 0.8067 - val_loss: 0.5761 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.76000\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4984 - acc: 0.8299 - val_loss: 0.5938 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.76000\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 5s 219ms/step - loss: 0.5248 - acc: 0.8367 - val_loss: 0.5511 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.76000 to 0.80000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial0-improvement-BEST.hdf5\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4634 - acc: 0.8667 - val_loss: 0.5686 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.80000\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4917 - acc: 0.8267 - val_loss: 0.6062 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.80000\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.5134 - acc: 0.8599 - val_loss: 0.5754 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.80000\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4709 - acc: 0.8499 - val_loss: 0.5496 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.80000\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 4s 162ms/step - loss: 0.4340 - acc: 0.8800 - val_loss: 0.5666 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.80000\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4092 - acc: 0.9368 - val_loss: 0.5646 - val_acc: 0.8400\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.80000 to 0.84000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial0-improvement-BEST.hdf5\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.3835 - acc: 0.9200 - val_loss: 0.5796 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.84000\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.3738 - acc: 0.9200 - val_loss: 0.5744 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.84000\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.3788 - acc: 0.9300 - val_loss: 0.5616 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.84000\n",
      "Epoch 00035: early stopping\n",
      "Trial 1\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 5s 201ms/step - loss: 0.9567 - acc: 0.5166 - val_loss: 0.8526 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.56000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial1-improvement-BEST.hdf5\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.9603 - acc: 0.4334 - val_loss: 0.8388 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.56000\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.9608 - acc: 0.4866 - val_loss: 0.8697 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.56000\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8364 - acc: 0.5598 - val_loss: 0.8308 - val_acc: 0.3600\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.56000\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.9106 - acc: 0.4934 - val_loss: 0.8195 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.56000\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 4s 160ms/step - loss: 0.8720 - acc: 0.5434 - val_loss: 0.8072 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.56000\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.8952 - acc: 0.5034 - val_loss: 0.8212 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.56000\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8400 - acc: 0.5498 - val_loss: 0.7837 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.56000\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 0.7889 - acc: 0.6034 - val_loss: 0.8034 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.56000\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.8512 - acc: 0.4802 - val_loss: 0.7772 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.56000 to 0.60000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial1-improvement-BEST.hdf5\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 0.8410 - acc: 0.5366 - val_loss: 0.7910 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.60000\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.8086 - acc: 0.5166 - val_loss: 0.7531 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.60000\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.7592 - acc: 0.6134 - val_loss: 0.7583 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.60000\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.7758 - acc: 0.6334 - val_loss: 0.7557 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.60000\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 0.7190 - acc: 0.6467 - val_loss: 0.6952 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.60000 to 0.76000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial1-improvement-BEST.hdf5\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 0.6960 - acc: 0.6899 - val_loss: 0.6116 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.76000 to 0.80000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial1-improvement-BEST.hdf5\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 0.6735 - acc: 0.7267 - val_loss: 0.6606 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.80000\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 0.6372 - acc: 0.7399 - val_loss: 0.6038 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.80000\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.6136 - acc: 0.6867 - val_loss: 0.5963 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.80000\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.5777 - acc: 0.7935 - val_loss: 0.6596 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.80000\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.5691 - acc: 0.7799 - val_loss: 0.5963 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.80000\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.5598 - acc: 0.7735 - val_loss: 0.5661 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.80000\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.4694 - acc: 0.8699 - val_loss: 0.5516 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.80000\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.5053 - acc: 0.8099 - val_loss: 0.5763 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.80000\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4498 - acc: 0.8800 - val_loss: 0.5770 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.80000\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4167 - acc: 0.9100 - val_loss: 0.5747 - val_acc: 0.6400\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.80000\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4267 - acc: 0.9100 - val_loss: 0.5352 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.80000\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4359 - acc: 0.8599 - val_loss: 0.5228 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.80000\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.3773 - acc: 0.9200 - val_loss: 0.5332 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.80000\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.3744 - acc: 0.9400 - val_loss: 0.5445 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.80000\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.3683 - acc: 0.9300 - val_loss: 0.5777 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.80000\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.3674 - acc: 0.9268 - val_loss: 0.5692 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.80000\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 0.3470 - acc: 0.9468 - val_loss: 0.5686 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.80000\n",
      "Epoch 00033: early stopping\n",
      "Trial 2\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 5s 206ms/step - loss: 1.0685 - acc: 0.4234 - val_loss: 0.9668 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.44000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial2-improvement-BEST.hdf5\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8924 - acc: 0.5834 - val_loss: 0.8674 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.44000\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.8999 - acc: 0.5134 - val_loss: 0.8513 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.44000\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8899 - acc: 0.4902 - val_loss: 0.8220 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.44000 to 0.56000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial2-improvement-BEST.hdf5\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 4s 163ms/step - loss: 0.8709 - acc: 0.4998 - val_loss: 1.1061 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.56000\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.9257 - acc: 0.4834 - val_loss: 0.8119 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.56000\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8904 - acc: 0.4966 - val_loss: 0.8408 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.56000\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8545 - acc: 0.4834 - val_loss: 0.8172 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.56000\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 4s 162ms/step - loss: 0.8355 - acc: 0.5398 - val_loss: 0.8790 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.56000\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 0.8490 - acc: 0.5266 - val_loss: 0.8344 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.56000\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.8867 - acc: 0.5002 - val_loss: 0.7522 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.56000 to 0.72000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial2-improvement-BEST.hdf5\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.7252 - acc: 0.6435 - val_loss: 0.8314 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.72000\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8158 - acc: 0.5734 - val_loss: 0.7071 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.72000\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.7692 - acc: 0.6034 - val_loss: 0.6820 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.72000 to 0.76000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial2-improvement-BEST.hdf5\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.7497 - acc: 0.6034 - val_loss: 0.7345 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.76000\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.7292 - acc: 0.6767 - val_loss: 0.6819 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.76000\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.6976 - acc: 0.6967 - val_loss: 0.6356 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.76000\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.6362 - acc: 0.7699 - val_loss: 0.5914 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.76000 to 0.80000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial2-improvement-BEST.hdf5\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.6283 - acc: 0.7667 - val_loss: 0.6028 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.80000\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.6378 - acc: 0.7467 - val_loss: 0.6224 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.80000\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.5700 - acc: 0.8199 - val_loss: 0.5990 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.80000\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.5348 - acc: 0.8467 - val_loss: 0.5778 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.80000\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4822 - acc: 0.8699 - val_loss: 0.6117 - val_acc: 0.6400\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.80000\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.5213 - acc: 0.7999 - val_loss: 0.5495 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.80000\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4493 - acc: 0.8767 - val_loss: 0.5404 - val_acc: 0.8400\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.80000 to 0.84000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial2-improvement-BEST.hdf5\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4527 - acc: 0.8667 - val_loss: 0.5564 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.84000\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.4769 - acc: 0.8835 - val_loss: 0.5838 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.84000\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4897 - acc: 0.8599 - val_loss: 0.5677 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.84000\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.4026 - acc: 0.9100 - val_loss: 0.5756 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.84000\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.3836 - acc: 0.9000 - val_loss: 0.5870 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.84000\n",
      "Epoch 00030: early stopping\n",
      "Trial 3\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 5s 218ms/step - loss: 0.9772 - acc: 0.4434 - val_loss: 0.8513 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.56000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial3-improvement-BEST.hdf5\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.9482 - acc: 0.5066 - val_loss: 0.8292 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.56000\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.9246 - acc: 0.4734 - val_loss: 0.8215 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.56000\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.8778 - acc: 0.5466 - val_loss: 0.8127 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.56000 to 0.60000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial3-improvement-BEST.hdf5\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8378 - acc: 0.5266 - val_loss: 0.8020 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.60000\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8087 - acc: 0.5498 - val_loss: 0.7985 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.60000\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8361 - acc: 0.4934 - val_loss: 0.7874 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.60000\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8544 - acc: 0.4898 - val_loss: 0.7921 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.60000\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8667 - acc: 0.4402 - val_loss: 0.7846 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.60000\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.7896 - acc: 0.4966 - val_loss: 0.7798 - val_acc: 0.4000\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.60000\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.8196 - acc: 0.4966 - val_loss: 0.7773 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.60000\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.7928 - acc: 0.5298 - val_loss: 0.7685 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.60000\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.8058 - acc: 0.5134 - val_loss: 0.7666 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.60000\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8153 - acc: 0.4466 - val_loss: 0.7775 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.60000\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.7757 - acc: 0.4766 - val_loss: 0.7757 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.60000\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.8192 - acc: 0.4634 - val_loss: 0.8179 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.60000\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.7710 - acc: 0.4998 - val_loss: 0.8185 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.60000\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 0.8101 - acc: 0.4434 - val_loss: 0.8062 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.60000\n",
      "Epoch 00018: early stopping\n",
      "Trial 4\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 6s 224ms/step - loss: 0.9954 - acc: 0.4802 - val_loss: 0.9210 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.44000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial4-improvement-BEST.hdf5\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 1.0031 - acc: 0.4034 - val_loss: 0.9808 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.44000\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.8809 - acc: 0.5134 - val_loss: 0.8319 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.44000\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8931 - acc: 0.5066 - val_loss: 0.8071 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.44000 to 0.56000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial4-improvement-BEST.hdf5\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 4s 162ms/step - loss: 0.8393 - acc: 0.5566 - val_loss: 0.8081 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.56000\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.8737 - acc: 0.4934 - val_loss: 0.8021 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.56000\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8552 - acc: 0.4534 - val_loss: 0.8021 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.56000\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8102 - acc: 0.5598 - val_loss: 0.7901 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.56000\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8294 - acc: 0.4366 - val_loss: 0.7793 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.56000\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.8648 - acc: 0.4566 - val_loss: 0.7541 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.56000 to 0.60000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial4-improvement-BEST.hdf5\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 0.7934 - acc: 0.5066 - val_loss: 0.7953 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.60000\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.7905 - acc: 0.5666 - val_loss: 0.6730 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.60000 to 0.68000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial4-improvement-BEST.hdf5\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.7534 - acc: 0.5398 - val_loss: 0.6981 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.68000 to 0.72000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial4-improvement-BEST.hdf5\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.7000 - acc: 0.6999 - val_loss: 0.6688 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.72000\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.6684 - acc: 0.6935 - val_loss: 0.6491 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.72000\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.6364 - acc: 0.6899 - val_loss: 0.5916 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.72000 to 0.80000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial4-improvement-BEST.hdf5\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 0.6467 - acc: 0.7699 - val_loss: 0.6036 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.80000\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 6s 246ms/step - loss: 0.5698 - acc: 0.7667 - val_loss: 0.5653 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.80000\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.5133 - acc: 0.7967 - val_loss: 0.5920 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.80000\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.5139 - acc: 0.7999 - val_loss: 0.5330 - val_acc: 0.8400\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.80000 to 0.84000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial4-improvement-BEST.hdf5\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 4s 158ms/step - loss: 0.5106 - acc: 0.8267 - val_loss: 0.5749 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.84000\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4748 - acc: 0.8399 - val_loss: 0.5492 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.84000\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4332 - acc: 0.9000 - val_loss: 0.5270 - val_acc: 0.8800\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.84000 to 0.88000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial4-improvement-BEST.hdf5\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4614 - acc: 0.8699 - val_loss: 0.5804 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.88000\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.4265 - acc: 0.8699 - val_loss: 0.5267 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.88000\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.3910 - acc: 0.9200 - val_loss: 0.5220 - val_acc: 0.8400\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.88000\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.3693 - acc: 0.8900 - val_loss: 0.5186 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.88000\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.4363 - acc: 0.8499 - val_loss: 0.5255 - val_acc: 0.8400\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.88000\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4001 - acc: 0.9300 - val_loss: 0.5595 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.88000\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.3738 - acc: 0.9100 - val_loss: 0.5544 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.88000\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 4s 162ms/step - loss: 0.3826 - acc: 0.8868 - val_loss: 0.5989 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.88000\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.3281 - acc: 0.9600 - val_loss: 0.5642 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.88000\n",
      "Epoch 00032: early stopping\n",
      "Trial 5\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 7s 294ms/step - loss: 0.9897 - acc: 0.5234 - val_loss: 0.8502 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.56000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial5-improvement-BEST.hdf5\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.9953 - acc: 0.4666 - val_loss: 0.8352 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.56000\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.8793 - acc: 0.4666 - val_loss: 0.8514 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.56000\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.8635 - acc: 0.4534 - val_loss: 0.8189 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.56000\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 0.8960 - acc: 0.5466 - val_loss: 0.8169 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.56000\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8826 - acc: 0.5034 - val_loss: 0.8326 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.56000\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.7912 - acc: 0.5502 - val_loss: 0.8058 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.56000\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.8877 - acc: 0.4566 - val_loss: 0.7723 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.56000 to 0.60000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial5-improvement-BEST.hdf5\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.8623 - acc: 0.5302 - val_loss: 0.8514 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.60000\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.8694 - acc: 0.4234 - val_loss: 0.7931 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.60000\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8224 - acc: 0.4934 - val_loss: 0.7551 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.60000\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 4s 161ms/step - loss: 0.7998 - acc: 0.5334 - val_loss: 0.7527 - val_acc: 0.6400\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.60000 to 0.64000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial5-improvement-BEST.hdf5\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.7664 - acc: 0.5966 - val_loss: 0.6786 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.64000 to 0.72000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial5-improvement-BEST.hdf5\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.6980 - acc: 0.7267 - val_loss: 0.6604 - val_acc: 0.6400\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.72000\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.7024 - acc: 0.6699 - val_loss: 0.6008 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.72000 to 0.80000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial5-improvement-BEST.hdf5\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.6262 - acc: 0.7499 - val_loss: 0.6044 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.80000\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 0.6085 - acc: 0.7599 - val_loss: 0.5453 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.80000\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.5415 - acc: 0.8199 - val_loss: 0.5767 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.80000\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4908 - acc: 0.8900 - val_loss: 0.5537 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.80000\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 4s 162ms/step - loss: 0.6006 - acc: 0.7699 - val_loss: 0.5602 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.80000\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.4999 - acc: 0.8567 - val_loss: 0.5096 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.80000\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4638 - acc: 0.8467 - val_loss: 0.5524 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.80000\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.4718 - acc: 0.8767 - val_loss: 0.5666 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.80000\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.4763 - acc: 0.8199 - val_loss: 0.5069 - val_acc: 0.8400\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.80000 to 0.84000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial5-improvement-BEST.hdf5\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4391 - acc: 0.8467 - val_loss: 0.5215 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.84000\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.3874 - acc: 0.9068 - val_loss: 0.5031 - val_acc: 0.8800\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.84000 to 0.88000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial5-improvement-BEST.hdf5\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4004 - acc: 0.8499 - val_loss: 0.5296 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.88000\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.3886 - acc: 0.8900 - val_loss: 0.5108 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.88000\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.3766 - acc: 0.9000 - val_loss: 0.5119 - val_acc: 0.8800\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.88000\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.3633 - acc: 0.9200 - val_loss: 0.5078 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.88000\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.3334 - acc: 0.9368 - val_loss: 0.5660 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.88000\n",
      "Epoch 00031: early stopping\n",
      "Trial 6\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 5s 219ms/step - loss: 0.9908 - acc: 0.5066 - val_loss: 0.8688 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.44000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial6-improvement-BEST.hdf5\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 4s 163ms/step - loss: 0.9553 - acc: 0.4998 - val_loss: 1.0169 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.44000\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.9334 - acc: 0.4634 - val_loss: 0.8413 - val_acc: 0.4000\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.44000\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 4s 162ms/step - loss: 0.8996 - acc: 0.4834 - val_loss: 0.8202 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.44000 to 0.56000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial6-improvement-BEST.hdf5\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8793 - acc: 0.4534 - val_loss: 0.8232 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.56000\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8661 - acc: 0.5134 - val_loss: 0.8611 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.56000\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8987 - acc: 0.4966 - val_loss: 0.7997 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.56000\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8667 - acc: 0.5566 - val_loss: 0.8023 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.56000\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.8621 - acc: 0.5266 - val_loss: 0.8218 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.56000\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.8484 - acc: 0.5134 - val_loss: 0.8045 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.56000\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8366 - acc: 0.5334 - val_loss: 0.8755 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.56000\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.8365 - acc: 0.5166 - val_loss: 0.7678 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.56000\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8448 - acc: 0.5902 - val_loss: 0.7970 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.56000\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.8257 - acc: 0.5366 - val_loss: 0.8025 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.56000\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.7723 - acc: 0.5934 - val_loss: 0.7836 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.56000\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.7694 - acc: 0.6034 - val_loss: 0.7345 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.56000 to 0.60000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial6-improvement-BEST.hdf5\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.7512 - acc: 0.6098 - val_loss: 0.7178 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.60000 to 0.72000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial6-improvement-BEST.hdf5\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 4s 162ms/step - loss: 0.7075 - acc: 0.6867 - val_loss: 0.7195 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.72000\n",
      "Epoch 19/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 4s 161ms/step - loss: 0.7022 - acc: 0.7299 - val_loss: 0.7104 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.72000\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.6668 - acc: 0.7267 - val_loss: 0.6943 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.72000\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.6437 - acc: 0.6835 - val_loss: 0.6308 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.72000\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 4s 162ms/step - loss: 0.6115 - acc: 0.7799 - val_loss: 0.6018 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.72000 to 0.76000, saving model to /analysis/fabiane/models/MS/pretrained/rebuild_64Net/new_script/weights-augm-trial6-improvement-BEST.hdf5\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.5930 - acc: 0.7967 - val_loss: 0.5806 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.76000\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.5178 - acc: 0.8499 - val_loss: 0.6046 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.76000\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 4s 162ms/step - loss: 0.5346 - acc: 0.8067 - val_loss: 0.6009 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.76000\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.5022 - acc: 0.8199 - val_loss: 0.5703 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.76000\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.4460 - acc: 0.8800 - val_loss: 0.6188 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.76000\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.4763 - acc: 0.8499 - val_loss: 0.5803 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.76000\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4160 - acc: 0.8800 - val_loss: 0.6278 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.76000\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4388 - acc: 0.8767 - val_loss: 0.5333 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.76000\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.4666 - acc: 0.8199 - val_loss: 0.5839 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.76000\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4131 - acc: 0.8900 - val_loss: 0.5923 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.76000\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.3762 - acc: 0.9100 - val_loss: 0.6621 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.76000\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.4083 - acc: 0.8767 - val_loss: 0.6337 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.76000\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 0.3469 - acc: 0.9500 - val_loss: 0.6068 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.76000\n",
      "Epoch 00035: early stopping\n",
      "Training Time: 0.0h:15.0m:31.875849962234497s\n",
      "Validation final accuracies: \n",
      " [0.76, 0.72, 0.76, 0.44, 0.68, 0.72, 0.76]\n",
      "Validation final accuracies mean: 0.6914285714285714\n",
      "Validation best accuracies: \n",
      " [0.84, 0.8, 0.84, 0.6, 0.88, 0.88, 0.76]\n",
      "Validation best accuracies mean: 0.7999999999999999\n",
      "Validation balanced accuracies: \n",
      " [0.7467532467532467, 0.7012987012987013, 0.7564935064935066, 0.5, 0.6655844155844155, 0.7207792207792207, 0.7272727272727273]\n",
      "Validation balanced accuracies mean: 0.6883116883116883\n"
     ]
    }
   ],
   "source": [
    "# training args\n",
    "lr = 0.0005\n",
    "lr_decay = 0.002\n",
    "transforms = [intensity, sagittal_flip, translate]\n",
    "\n",
    "num_trials = 7\n",
    "store_models = True\n",
    "\n",
    "# callbacks\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "accuracies = []\n",
    "balanced_accuracies = []\n",
    "max_acc = []\n",
    "\n",
    "for i in range(num_trials):\n",
    "    print(\"Trial %i\" %i)\n",
    "    \n",
    "    # init model\n",
    "    model = init_model(model_path, finetune=False, up_to=None)    \n",
    "    opti = Adam(lr=lr, decay=lr_decay)\n",
    "    model.compile(optimizer=opti, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # callbacks\n",
    "    earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "    if store_models:\n",
    "        result_path = os.path.join(result_dir, \"weights-augm-trial%i-improvement-BEST.hdf5\" %i)\n",
    "        model_checkpoint = ModelCheckpoint(result_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max', save_weights_only=True)\n",
    "        callbacks = [earlystop, model_checkpoint]\n",
    "    else:\n",
    "        callbacks = [earlystop]\n",
    "        \n",
    "    train_loader = CISDataset(X_train, y_train, transform=transforms, batch_size=b, shuffle=True)\n",
    "    val_loader = CISDataset(X_val, y_val, transform=[intensity], batch_size=1, shuffle=False)\n",
    "    \n",
    "    # Start training\n",
    "    history = model.fit_generator(train_loader,\n",
    "                        epochs=num_epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=val_loader,\n",
    "                        callbacks=callbacks)\n",
    "    \n",
    "    # Evaluation\n",
    "    y_pred = model.predict_generator(val_loader)\n",
    "    #y_true = [item for sublist in [val_loader[batch_idx][1] for batch_idx in range(len(val_loader))] for item in sublist]\n",
    "    bal_acc = balanced_accuracy(y_val, y_pred>0.5)\n",
    "    accuracies.append(history.history[\"val_acc\"][-1])\n",
    "    balanced_accuracies.append(bal_acc)\n",
    "    max_acc.append(np.max(history.history[\"val_acc\"]))\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(\"Training Time: {}h:{}m:{}s\".format(\n",
    "            training_time//3600, (training_time//60)%60, training_time%60))\n",
    "\n",
    "print(\"Validation final accuracies: \\n {}\".format(accuracies))\n",
    "print(\"Validation final accuracies mean: {}\".format(np.mean(accuracies)))\n",
    "print(\"Validation best accuracies: \\n {}\".format(max_acc))\n",
    "print(\"Validation best accuracies mean: {}\".format(np.mean(max_acc)))\n",
    "print(\"Validation balanced accuracies: \\n {}\".format(balanced_accuracies))\n",
    "print(\"Validation balanced accuracies mean: {}\".format(np.mean(balanced_accuracies)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = [\"weights-augm-trial0-improvement-BEST.hdf5\",\n",
    "           \"weights-augm-trial1-improvement-BEST.hdf5\",\n",
    "           \"weights-augm-trial2-improvement-BEST.hdf5\",\n",
    "           \"weights-augm-trial3-improvement-BEST.hdf5\",\n",
    "           \"weights-augm-trial4-improvement-BEST.hdf5\",\n",
    "           \"weights-augm-trial5-improvement-BEST.hdf5\",\n",
    "           \"weights-augm-trial6-improvement-BEST.hdf5\",\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load holdout set\n",
    "test_loader = CISDataset(X_holdout, y_holdout, transform=[intensity], batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabiane/anaconda2/envs/postal/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy 82.61 %\n",
      "Balanced accuracy 82.31 %\n",
      "Fold 1\n",
      "Model accuracy 82.61 %\n",
      "Balanced accuracy 84.62 %\n",
      "Fold 2\n",
      "Model accuracy 91.30 %\n",
      "Balanced accuracy 92.31 %\n",
      "Fold 3\n",
      "Model accuracy 43.48 %\n",
      "Balanced accuracy 50.00 %\n",
      "Fold 4\n",
      "Model accuracy 91.30 %\n",
      "Balanced accuracy 92.31 %\n",
      "Fold 5\n",
      "Model accuracy 91.30 %\n",
      "Balanced accuracy 92.31 %\n",
      "Fold 6\n",
      "Model accuracy 86.96 %\n",
      "Balanced accuracy 87.31 %\n",
      "######## Final results ########\n",
      "Accuracy mean 81.37 %\n",
      "Balanced accuracy mean 83.02 %\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "balanced_accuracies = []\n",
    "for fold, weight in enumerate(weights):\n",
    "    print(\"Fold {}\".format(fold))\n",
    "    model = load_model(model_path)\n",
    "    model_dir = os.path.join(result_dir, weight)\n",
    "    model.load_weights(model_dir)\n",
    "    \n",
    "    opti = Adam(lr=lr, decay=lr_decay)\n",
    "    model.compile(optimizer=opti,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    res = model.evaluate_generator(test_loader)\n",
    "    print(\"Model accuracy {:.2f} %\".format(res[1]*100))\n",
    "    \n",
    "    y_pred = (model.predict_generator(test_loader) > 0.5) * 1\n",
    "    bal_acc = balanced_accuracy(y_holdout, y_pred)\n",
    "    print(\"Balanced accuracy {:.2f} %\".format(bal_acc*100))\n",
    "    \n",
    "    accuracies.append(res[1])\n",
    "    balanced_accuracies.append(bal_acc)\n",
    "print(\"######## Final results ########\")\n",
    "print(\"Accuracy mean {:.2f} %\".format(np.mean(accuracies)*100))\n",
    "print(\"Balanced accuracy mean {:.2f} %\".format(np.mean(balanced_accuracies)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 0.0h:15.0m:31.88907742500305s\n",
      "Total time elapsed: 0.0h:16.0m:18.07839822769165s\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Time: {}h:{}m:{}s\".format(\n",
    "            training_time//3600, (training_time//60)%60, training_time%60))\n",
    "print(\"Total time elapsed: {}h:{}m:{}s\".format(\n",
    "            total_time//3600, (total_time//60)%60, total_time%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (postal)",
   "language": "python",
   "name": "postal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
